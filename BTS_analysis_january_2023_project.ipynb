{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "HRLkJYpBAvvm",
        "A6duJhggDIgt",
        "-8YJDiVNDOtx",
        "7_pcO3i7EiFl",
        "UyZADm2sHdVV",
        "V7i5f90kIiJz",
        "GrZ2w5MOxQwL",
        "5lXizFUP8AVA",
        "CsHsnIzh_za7",
        "EAjxeM7Y2JVT",
        "JYQgp_Ba3b2O",
        "vz4N5xeK73Zb",
        "L_oaDchB99iL",
        "GyFFrmwOJtF9",
        "vHFAEWGS5nLv",
        "T7xZxlZF55nY",
        "sS5P1QFM57bG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pereirasbruna/trafego_aereo_eua_jan_23/blob/main/BTS_analysis_january_2023_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Projeto IV - Análise de voos domésticos atrasados e cancelados em janeiro de 2023 nos EUA.\n",
        "\n"
      ],
      "metadata": {
        "id": "O7ABfN7zKDqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Informações sobre o Projeto:"
      ],
      "metadata": {
        "id": "af08IzdyFgrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cliente, contexto, objetivos e hipóteses:"
      ],
      "metadata": {
        "id": "HRLkJYpBAvvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Bureau of Transportation Statistics (BTS) é um órgão estadunidense responsável pela coleta, análise e divulgação de dados sobre o sistema de transporte do país, fazendo parte do Departamento de Nacional de Transportes. Neste sentido, a DataLab foi contratada para auxiliar na análise destes dados. O objetivo da análise solicitada foi de examinar as companhias operantes de voos domésticos no país, principalmente indicadores de voos cancelados e atrasados. Com os resultados desenvolvidos, o órgão americano poderia reconhecer alguns problemas que influenciaram o fluxo de trafego aereo no pais durante o período de janeiro de 2023.\n",
        "\n",
        "**As questões de negócios trazidas pelo órgão estadunidense foram:**\n",
        "\n",
        "- Feriados nacionais influenciaram no aumento de atrasos de voos em janeiro de 2023? Os feriados analisados foram 01 e 02 de janeiro (ano novo) e 16 de janeiro (Dia de Martin Luther King).\n",
        "\n",
        "- Condições climáticas adversas foram um fator determinante para o aumento do número de cancelamentos de voos em janeiro de 2023? Foram considerados condições adversas névoa (fog), chuva de forte intensidade (heavy intensity rain), fumaça (smoke), tempestade (thunderstorm), tempestade com chuva forte (thunderstorm with heavy rain) e tempestade com chuva leve (thunderstorm with light rain).\n",
        "\n",
        "- Quais são as 5 companhias aéreas com as maiores taxas de atraso e cancelamento em janeiro de 2023? Quantidade absoluta e quantidade normalizada.\n",
        "\n",
        "- Os cinco aeroportos com maior fluxo de voôs em janeiro de 2023 são os que mais sofreram cancelamento neste período?\n",
        "\n",
        "**Neste sentido, foram criadas as seguintes hipóteses:**\n",
        "\n",
        "- Os feriados nacionais nos EUA influenciaram no aumento dos atrasos de voos em janeiro de 2023.\n",
        "\n",
        "- Condições climáticas adversas, como névoa, chuva de forte intensidade, fumaça, tempestade, tempestade com chuva forte e tempestade com chuva leve, foram fatores determinantes para o aumento do número de cancelamentos de voos em janeiro de 2023.\n",
        "\n",
        "- As 5 companhias aéreas com maior fluxo de voos domésticos estão relacionadas com as maiores taxas de atraso em janeiro de 2023 nos EUA.\n",
        "\n",
        "- Os cinco aeroportos com maior fluxo de voos em janeiro de 2023 são os que mais sofreram cancelamentos durante este período."
      ],
      "metadata": {
        "id": "f-_Zoe6hAuGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Informações sobre equipe e ferramentas"
      ],
      "metadata": {
        "id": "A6duJhggDIgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Equipe:\n"
      ],
      "metadata": {
        "id": "-8YJDiVNDOtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bruna Paiva:**\n",
        "- Github: https://github.com/bsap16\n",
        "- LinkedIn: http://www.linkedin.com/in/bruna-paiva16\n",
        "- E-mail: brunasap16@gmail.com\n",
        "\n",
        "**Bruna Pereira:**\n",
        "- Github: https://github.com/pereirasbruna\n",
        "-LinkedIn: https://www.linkedin.com/in/brunapereiras/\n",
        "-E-mail: brunapereiradossantos@live.com\n"
      ],
      "metadata": {
        "id": "r_EmASJ9EZpB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Ferramentas:"
      ],
      "metadata": {
        "id": "7_pcO3i7EiFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linguagem para limpeza de dados:**\n",
        "- Pyhton (Google Colab).\n",
        "\n",
        "**Visualização de dados:**\n",
        "- Power BI;\n",
        "- Figma.\n",
        "\n",
        "**Apresentação dos dados:**\n",
        "- Google Apresentações.\n",
        "\n",
        "**Apresentação dos dados via vídeo:**\n",
        "- Loom."
      ],
      "metadata": {
        "id": "m7ltUa4GEoGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Informações sobre a base de dados informada pelo cliente\n"
      ],
      "metadata": {
        "id": "x24l55TICpPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tabela AIRLINECODEDICTIONARY\n",
        "\n",
        "| **Campo**     | **Descrição**                                             |\n",
        "|---------------|-----------------------------------------------------------|\n",
        "| Code          | Código exclusivo do operador para agências operadoras de aeronaves |\n",
        "| Description   | Descrição do órgão operador da aeronave                   |\n",
        "\n",
        "#### Tabela voos_202301\n",
        "\n",
        "| **Campo**               | **Descrição**                                                                                        |\n",
        "|-------------------------|------------------------------------------------------------------------------------------------------|\n",
        "| FL_DATE                 | Data do voo (aaaammdd)                                                                             |\n",
        "| AIRLINE_CODE            | Código exclusivo da operadora. Quando vários operadores utilizam o mesmo código, um sufixo numérico é usado para diferenciá-los, por exemplo, PA, PA(1), PA(2). |\n",
        "| DOT_CODE                | Número de identificação atribuído pelo US DOT para identificar uma companhia aérea única (transportadora). Uma companhia aérea única é definida como aquela que possui e reporta sob o mesmo certificado DOT independentemente do seu código, nome ou holding/sociedade. |\n",
        "| FL_NUMBER               | Número do voo                                                                                      |\n",
        "| ORIGIN                  | Aeroporto de origem                                                                               |\n",
        "| ORIGIN_CITY             | Nome da cidade do aeroporto de origem                                                               |\n",
        "| DEST                    | Aeroporto de destino                                                                              |\n",
        "| DEST_CITY               | Nome da cidade do aeroporto de destino                                                              |\n",
        "| CRSDEPTIME              | Hora de partida registrada no CRS (Sistema de Controle de Reservas) (horário local: hhmm)          |\n",
        "| DEP_TIME                | Hora real de partida (hora local: hhmm)                                                             |\n",
        "| DEP_DELAY               | Diferença em minutos entre o horário de partida programado e o real. Saídas antecipadas apresentam números negativos. |\n",
        "| TAXI_OUT                | Tempo de táxi na saída em minutos (táxi é o processo de mover um avião enquanto ele está na pista) |\n",
        "| WHEELS_OFF              | Hora exata de decolagem (hora local: hhmm)                                                          |\n",
        "| WHEELS_ON               | Hora exata de pouso (hora local: hhmm)                                                              |\n",
        "| TAXI_IN                 | Tempo de táxi na chegada em minutos                                                                 |\n",
        "| CRSARRTIME              | Hora de chegada registrada no CRS (hora local: hhmm)                                                |\n",
        "| ARR_TIME                | Hora real de chegada (hora local: hhmm)                                                             |\n",
        "| ARR_DELAY               | Diferença em minutos entre o horário previsto de chegada e o real. Chegadas antecipadas mostram números negativos. |\n",
        "| CANCELLED               | Indicador de voo cancelado (1=Sim)                                                                   |\n",
        "| CANCELLATION_CODE       | Especifica o motivo do cancelamento                                                                 |\n",
        "| DIVERTED                | Indicador de voo desviado (1=Sim)                                                                    |\n",
        "| CRSELAPSEDTIME          | Tempo total de voo decorrido em minutos registrado no CRS                                           |\n",
        "| ELAPSED_TIME            | Tempo total de voo decorrido em minutos reais                                                       |\n",
        "| AIR_TIME                | Tempo de voo no ar em minutos                                                                       |\n",
        "| DISTANCE                | Distância entre aeroportos (milhas)                                                                 |\n",
        "| DELAYDUECARRIER         | Atraso da operadora em minutos                                                                       |\n",
        "| DELAYDUEWEATHER         | Atraso climático em minutos                                                                         |\n",
        "| DELAYDUENAS            | Atraso do Sistema Aéreo Nacional em minutos                                                          |\n",
        "| DELAYDUESECURITY        | Atraso de segurança em minutos                                                                       |\n",
        "| DELAYDUELATE_AIRCRAFT   | Atraso de aeronaves atrasadas em minutos                                                             |\n"
      ],
      "metadata": {
        "id": "gpmR_2AhC-qO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importação de bibliotecas:"
      ],
      "metadata": {
        "id": "UyZADm2sHdVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Realizado somente uma vez\n",
        "!pip install mplcursors\n"
      ],
      "metadata": {
        "id": "sc5tgmC8H-0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Manipulação e análise de dados em estruturas de dados\n",
        "import requests  # Envio de solicitações HTTP\n",
        "from IPython.display import display  # Exibição de objetos no Jupyter Notebook\n",
        "import ipywidgets as widgets  # Criação de widgets interativos no Jupyter Notebook\n",
        "import numpy as np  # Operações matemáticas e suporte a arrays multidimensionais\n",
        "import matplotlib.pyplot as plt  # Criação de gráficos e visualizações\n",
        "import matplotlib as mpl  # Configuração e controle do comportamento do matplotlib\n",
        "import seaborn as sns  # Visualização de dados baseada no matplotlib, com estilo e cores aprimoradas\n",
        "import missingno as msno  # Visualização de dados ausentes\n",
        "from wordcloud import WordCloud  # Criação de nuvens de palavras\n",
        "from google.colab import data_table  # Exibição de tabelas no Google Colab\n",
        "from google.colab import files  # Manipulação de arquivos no Google Colab\n",
        "from scipy.stats import chi2_contingency  # Teste de independência em tabelas de contingência\n",
        "from datetime import datetime  # Manipulação de datas e horários\n",
        "import mplcursors  # Criação de interações com gráficos matplotlib\n",
        "from scipy import stats #analises estatisticas\n",
        "from scipy.stats import chi2_contingency #para o teste de qui-quadrado"
      ],
      "metadata": {
        "id": "SxW2cgkYHplv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Leitura da base de dados"
      ],
      "metadata": {
        "id": "V7i5f90kIiJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_principal = pd.read_csv('flights_202301.csv')\n",
        "#df_airlines_code = pd.read_csv('AIRLINE_CODE_DICTIONARY.csv')\n",
        "#df_airlines_dot_code_csv = pd.read_excel('DOT_CODE_DICTIONARY.xlsx')\n",
        "df_principal = pd.read_csv('aeroportos_eua.csv')\n",
        "#df_feriados = pd.read_excel('feriados.xslx')\n"
      ],
      "metadata": {
        "id": "gbp3y4JZIq7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tratamento e análise de dados nulos"
      ],
      "metadata": {
        "id": "GrZ2w5MOxQwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo realiza a soma da presença de dados nulos por coluna no banco de dados."
      ],
      "metadata": {
        "id": "XHrBdiPnxzt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_values = df_principal.isnull()\n",
        "total_null_values_column = null_values.sum()\n",
        "total_nulls = null_values.sum().sum()\n",
        "print(\"Total de valores nulos por coluna:\")\n",
        "print(total_null_values_column)\n",
        "\n",
        "print(\"\\nTotal de valores nulos em todo o banco de dados:\", total_nulls)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0UvVmrTuxg3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao rodar o código, foram encontrados os valores abaixo:\n",
        "\n",
        "\n",
        "*   DEP_TIME:                     9978\n",
        "*   DEP_DELAY:                    9982\n",
        "*   TAXI_OUT:                    10197\n",
        "*   WHEELS_OFF:                  10197\n",
        "*   WHEELS_ON:                   10519\n",
        "*   TAXI_IN:                     10519\n",
        "*   ARR_TIME:                    10519\n",
        "*   ARR_DELAY:                   11640\n",
        "*   ELAPSED_TIME:                11640\n",
        "*   AIR_TIME:                    11640\n",
        "*   DELAY_DUE_CARRIER:          422124\n",
        "*   DELAY_DUE_WEATHER:          422124\n",
        "*   DELAY_DUE_NAS:              422124\n",
        "*   DELAY_DUE_SECURITY:         422124\n",
        "*   DELAY_DUE_LATE_AIRCRAFT:    422124\n",
        "\n",
        "Onde as informações abaixo ocorreram por causa cancelamentos e desvios:\n",
        "*   DEP_TIME:                     9978\n",
        "*   DEP_DELAY:                    9982\n",
        "*   TAXI_OUT:                    10197\n",
        "*   WHEELS_OFF:                  10197\n",
        "*   WHEELS_ON:                   10519\n",
        "*   TAXI_IN:                     10519\n",
        "*   ARR_TIME:                    10519\n",
        "*   ARR_DELAY:                   11640\n",
        "*   ELAPSED_TIME:                11640\n",
        "*   AIR_TIME:                    11640\n",
        "\n",
        "E as informações abaixo ocorreram por causa de atrasos onde os motivos não foram registrados, pois valores preenchidos com 0 nestas colunas informam que não ouve atraso:\n",
        "*   DELAY_DUE_CARRIER:          422124\n",
        "*   DELAY_DUE_WEATHER:          422124\n",
        "*   DELAY_DUE_NAS:              422124\n",
        "*   DELAY_DUE_SECURITY:         422124\n",
        "*   DELAY_DUE_LATE_AIRCRAFT:    422124"
      ],
      "metadata": {
        "id": "7-jQn1_K0ZQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo confirma a suposição que todos os voos encontrados como nulos na coluna DEP_DELAY são voos caracterizados como cancelados."
      ],
      "metadata": {
        "id": "GJCpLw0d2Izy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar quantos nulos referente a coluna DEP_DELAY eram relacionados com voos cancelados.\n",
        "dep_delay_null = df_principal[df_principal['DEP_DELAY'].isnull()]\n",
        "\n",
        "# Mostrar os valores correspondentes na coluna CANCELLED\n",
        "cancelled_when_dep_delay_null = dep_delay_null['CANCELLED']\n",
        "\n",
        "# Supondo que cancelled_when_dep_delay_null.value_counts() retorna uma série com a contagem\n",
        "count_canceled = cancelled_when_dep_delay_null.value_counts().get(1, 0)\n",
        "\n",
        "# Imprimindo o texto com o valor da contagem\n",
        "print(f\"Contagem de voos cancelados quando 'dep_delay' é nulo: {count_canceled}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tQoyzmjQ1BCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo confirma a suposição que todos os voos encontrados como nulos na coluna DEP_TIME são voos caracterizados como desviados."
      ],
      "metadata": {
        "id": "kRnqf_pR51yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar quantos nulos referente a coluna DEP_TIME eram relacionados com voos desviados.\n",
        "dep_delay_null = df_principal[df_principal['DEP_TIME'].isnull()]\n",
        "\n",
        "# Mostrar os valores correspondentes na coluna DIVERTED\n",
        "diverted_when_dep_delay_null = dep_delay_null['DIVERTED']\n",
        "\n",
        "# Supondo que diverted_when_dep_delay_null.value_counts() retorna uma série com a contagem\n",
        "count_diverted = diverted_when_dep_delay_null.value_counts().get(1, 0)\n",
        "\n",
        "# Exibir os valores únicos e suas contagens\n",
        "print(diverted_when_dep_delay_null.value_counts())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "d0JJCdjP3Vra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo foi realizado uma análise referente aos voos atrasados e seus respectivos motivos, sendo eles:\n",
        "- Voo posteriormente cancelado;\n",
        "- Voo posteriormente desviado;\n",
        "- Causa do atraso informada pela BTS;\n",
        "- Causa do atraso não informada pela BTS;"
      ],
      "metadata": {
        "id": "1yqcZT_kxGkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtrar voos atrasados com causa não informada pela BTS\n",
        "df_atrasados_causa_desconhecida = df_principal[(df_principal['DEP_DELAY'] >= 1) & (df_principal['DELAY_DUE_CARRIER'].isnull())]\n",
        "\n",
        "#Filtrar voos atrasados com causa informada pela BTS\n",
        "df_atrasados_causa_conhecida = df_principal[(df_principal['DEP_DELAY'] >= 1) & (df_principal['DELAY_DUE_CARRIER'].notnull())]\n",
        "\n",
        "#Filtrar voos atrasados cancelados e desviados\n",
        "df_atrasados_cancelados = df_atrasados_causa_desconhecida[(df_atrasados_causa_desconhecida['CANCELLED'] == 1)]\n",
        "df_atrasados_desviados = df_atrasados_causa_desconhecida[(df_atrasados_causa_desconhecida['DIVERTED'] == 1)]\n",
        "\n",
        "#Filtrar voos atrasados\n",
        "voos_atrasados = df_principal[df_principal['DEP_DELAY'] >= 1]\n",
        "\n",
        "#Calcular o total de voos atrasados\n",
        "total_voos_atrasados = len(voos_atrasados)\n",
        "total_voos_atrasados_causa_conhecida = len(df_atrasados_causa_conhecida)\n",
        "total_voos_atrasados_causa_desconhecida = len(df_atrasados_causa_desconhecida) - len(df_atrasados_cancelados) - len(df_atrasados_desviados)\n",
        "\n",
        "# Calcular porcentagens\n",
        "percent_atrasados_causa_conhecida = (len(df_atrasados_causa_conhecida) / total_voos_atrasados) * 100\n",
        "percent_atrasados_causa_desconhecida = (len(df_atrasados_causa_desconhecida) / total_voos_atrasados) * 100\n",
        "percent_cancelados = (len(df_atrasados_cancelados) / total_voos_atrasados) * 100\n",
        "percent_desviados = (len(df_atrasados_desviados) / total_voos_atrasados) * 100\n",
        "\n",
        "\n",
        "# Calcular porcentagens\n",
        "percent_atrasados_causa_desconhecida = (len(df_atrasados_causa_desconhecida) / total_voos_atrasados) * 100\n",
        "percent_cancelados = (len(df_atrasados_cancelados) / total_voos_atrasados) * 100\n",
        "percent_desviados = (len(df_atrasados_desviados) / total_voos_atrasados) * 100\n",
        "percent_atrasados_causa_conhecida_sem_cancelados_desviados = (total_voos_atrasados_causa_desconhecida / total_voos_atrasados) * 100\n",
        "\n",
        "# Exibir a quantidade de voos atrasados e sua porcentagem\n",
        "print(f\"Quantidade de voos atrasados: {total_voos_atrasados}\")\n",
        "print(f\"Quantidade de voos atrasados com causa informada: {total_voos_atrasados_causa_conhecida} - {percent_atrasados_causa_conhecida:.2f}% do total de voos atrasados\")\n",
        "print(f\"Quantidade de voos atrasados com causa não informada: {len(df_atrasados_causa_desconhecida)} - {percent_atrasados_causa_desconhecida:.2f}% do total de voos atrasados\")\n",
        "\n",
        "print(f\"Destes voos com a causa de atraso não informada pela BTS, são:\")\n",
        "print(f\"Quantidade de voos atrasados que foram cancelados posteriormente: {len(df_atrasados_cancelados)} - {percent_cancelados:.2f}% do total de voos atrasados\")\n",
        "print(f\"Quantidade de voos atrasados que foram desviados posteriormente: {len(df_atrasados_desviados)} - {percent_desviados:.2f}% do total de voos atrasados\")\n",
        "print(f\"Quantidade de voos atrasados que faltam informações referente a motivos: {total_voos_atrasados_causa_desconhecida} - {percent_atrasados_causa_conhecida_sem_cancelados_desviados:.2f}% do total de voos atrasados\")"
      ],
      "metadata": {
        "id": "aXtPuhJD6AYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Quantidade de voos atrasados: 202779\n",
        "- Quantidade de voos atrasados com causa informada: 102013 - 50.31% do total de voos atrasados\n",
        "- Quantidade de voos atrasados com causa não informada: 100766 - 49.69% do total de voos atrasados\n",
        "\n",
        "Destes voos com a causa de atraso não informada pela BTS, são:\n",
        "- Quantidade de voos atrasados que foram cancelados posteriormente: 208 - 0.10% do total de voos atrasados\n",
        "- Quantidade de voos atrasados que foram desviados posteriormente: 718 - 0.35% do total de voos atrasados\n",
        "- Quantidade de voos atrasados que faltam informações referente a motivos: 99840 - 49.24% do total de voos atrasados"
      ],
      "metadata": {
        "id": "MiKNwPXWyEdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo foi possível ver a relação de atrasados por companhia aerea em janeiro de 2023."
      ],
      "metadata": {
        "id": "QM2d5xMMSsq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar voos atrasados com causa desconhecida\n",
        "df_atrasados_causa_desconhecida = df_principal[(df_principal['DEP_DELAY'] >= 1) & (df_principal['DELAY_DUE_CARRIER'].isnull())]\n",
        "\n",
        "# Calcular a frequência de cada aeroporto na coluna 'AIRLINE_DESCRIPTION'\n",
        "frequencia_linhas_aereas = df_atrasados_causa_desconhecida['AIRLINE_DESCRIPTION'].value_counts()\n",
        "\n",
        "# Transformar em DataFrame e renomear as colunas\n",
        "df_frequencia_linhas_aereas = frequencia_linhas_aereas.reset_index().rename(columns={'AIRLINE_DESCRIPTION': 'Linha aérea', 'count' : 'Quantidade de atrasos em 01/23'})\n",
        "\n",
        "# Ordenar por frequência em ordem decrescente\n",
        "df_frequencia_linhas_aereas_ordenado = df_frequencia_linhas_aereas.sort_values(by='Quantidade de atrasos em 01/23', ascending=False)\n",
        "\n",
        "# Exibir o DataFrame resultante\n",
        "display('Frequência de linhas aéreas com voos atrasados e causa desconhecida:')\n",
        "display(df_frequencia_linhas_aereas_ordenado)"
      ],
      "metadata": {
        "id": "sGFVjkZnx00E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construção de uma lista ordenada por quantidade onde possui os aeroportos com a maior quantidade de omissão de informações de motivo de atraso."
      ],
      "metadata": {
        "id": "aBDQzg9QXcV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar voos atrasados com causa desconhecida\n",
        "df_atrasados_causa_desconhecida = df_principal[(df_principal['DEP_DELAY'] >= 1) & (df_principal['DELAY_DUE_CARRIER'].isnull())]\n",
        "\n",
        "# Calcular a frequência de cada aeroporto na coluna 'ORIGIN'\n",
        "frequencia_aeroportos = df_atrasados_causa_desconhecida['ORIGIN_CITY'].value_counts()\n",
        "\n",
        "# Transformar em DataFrame e renomear as colunas\n",
        "df_frequencia_aeroportos = frequencia_aeroportos.reset_index().rename(columns={'ORIGIN_CITY': 'Aeroporto', 'count' : 'Quantidade de atrasos em 01/23'})\n",
        "\n",
        "# Ordenar por frequência em ordem decrescente\n",
        "df_frequencia_aeroportos_ordenado = df_frequencia_aeroportos.sort_values(by='Quantidade de atrasos em 01/23', ascending=False)\n",
        "\n",
        "# Exibir o DataFrame resultante\n",
        "display('Frequência de aeroportos com voos atrasados e causa desconhecida:')\n",
        "display(df_frequencia_aeroportos_ordenado[:10])"
      ],
      "metadata": {
        "id": "EyhdwQDMXFXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi encontrado um valor nulo na coluna CRS_ELAPSED_TIME, onde foi reconhecido que foi erro de preenchimento, visto que CRS_ELAPSED_TIME é um tempo padrão estabelecido pela BTS. Como não influenciava nas análises solicitadas pelo cliente, a informação permaneceu nula. Abaixo é possível analisar a informação encontrada."
      ],
      "metadata": {
        "id": "QaQDOx3AYJ7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar a linha com valor nulo em 'CRS_ELAPSED_TIME'\n",
        "linha_nula = df_principal[df_principal['CRS_ELAPSED_TIME'].isnull()]\n",
        "\n",
        "# Verificar o número de linhas encontradas\n",
        "if len(linha_nula) == 1:\n",
        "  # Converter a linha em um dicionário\n",
        "  dicionario_linha_nula = linha_nula.iloc[0].to_dict()\n",
        "\n",
        "  # Imprimir o dicionário\n",
        "  display(\"Valores da linha com CRS_ELAPSED_TIME nulo:\")\n",
        "  display(dicionario_linha_nula)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yhugR3jBX2N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para analisar os valores nulos, foi gerado um dendograma. Um dendrograma é um tipo de gráfico em árvore que mostra como diferentes colunas de um banco de dados estão relacionadas em termos de seus padrões de valores ausentes."
      ],
      "metadata": {
        "id": "GloF4KgJxdgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msno.dendrogram(df_principal)"
      ],
      "metadata": {
        "id": "lzDfl7oDvs04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretando o dendrograma de cima para baixo é possível notar as variáveis\n",
        "que se conectam ou por terem os mesmos nulos, ou por serem preenchidas com os mesmos dados, ou o equilibrio de uma estar preenchida enquanto outra está nula.\n",
        "\n",
        "É possível entender quais variáveis são interessantes para observar a correleção e entender melhor os porquês dos dados serem nulos."
      ],
      "metadata": {
        "id": "WCv5R-ugybgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O grafico abaixo permite ver rapidamente quantos valores ausentes existem em cada coluna do banco de dados. Os números acima mostram a quantidade de valores informados, e os espaços em branco informam a quantidade de valores faltantes. É possível perceber que nas colunas de motivos de atraso possuem um valor maior de valores nulos, confirmando a hipotese de valores omitidos."
      ],
      "metadata": {
        "id": "nIeVjBoL3bMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(df_principal)"
      ],
      "metadata": {
        "id": "tQ1hKkJrzMU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função msno.heatmap da biblioteca missingno foi utilizada para visualizar a correlação de valores ausentes entre diferentes colunas do banco de dados."
      ],
      "metadata": {
        "id": "MESn7aaj7mgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msno.heatmap(df_principal)"
      ],
      "metadata": {
        "id": "yOc1HAJN4Z89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tratamento e análise de dados duplicados"
      ],
      "metadata": {
        "id": "5lXizFUP8AVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo verifica a presença de duplicadas no banco de dados. Nesta análise não foram encontradas informações duplicadas."
      ],
      "metadata": {
        "id": "_ZbsDcfC8oR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#verifica duplicatas em todo o arquivo:\n",
        "duplicatas = df_principal[df_principal.duplicated()]\n",
        "\n",
        "#Mensagem personalizada para informar a quantidade de duplicatas encontradas:\n",
        "if duplicatas.empty:\n",
        "    print(\"\\nNúmero total de duplicatas: Nenhuma\")\n",
        "else:\n",
        "    print(\"\\nNúmero total de duplicatas:\", len(duplicatas))\n",
        "    print(duplicatas)"
      ],
      "metadata": {
        "id": "D3Gf6xpD8HFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dados fora do escopo de análise\n"
      ],
      "metadata": {
        "id": "CsHsnIzh_za7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todas as colunas possuem informações relevantes para análise. Neste sentido, iremos manter todas as variáveis. Referente as colunas, foram realizados testes para verificar se todas estão dentro do intervalo esperado e se possuem as características necessárias."
      ],
      "metadata": {
        "id": "2mjGf2x5_24f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar se a coluna AIRLINE_CODE possui exatamente 2 caracteres, entre números e letras.\n",
        "coluna_airline_code = 'AIRLINE_CODE'\n",
        "linhas_fora_de_escopo_airline_code = df_principal[~df_principal[coluna_airline_code].apply(lambda x: len(str(x)) == 2 and str(x).isalnum())]\n",
        "if linhas_fora_de_escopo_airline_code.empty:\n",
        "    print(f\"Todas as linhas na coluna {coluna_airline_code} possuem exatamente 2 caracteres (números ou letras).\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_airline_code} possuem caracteres diferentes de 2 ou não são alfanuméricos.\")\n",
        "    print(linhas_fora_de_escopo_airline_code)\n",
        "\n",
        "#Verificar se a coluna AIRLINE_DESCRIPTION possui somente letras e espaços em branco.\n",
        "coluna_airline_description = 'AIRLINE_DESCRIPTION'\n",
        "linhas_fora_de_escopo_airline_description = df_principal[df_principal[coluna_airline_description].str.contains(r'[^a-zA-Z\\s\\.]', regex=True, na=False)]\n",
        "if linhas_fora_de_escopo_airline_description.empty:\n",
        "    print(f\"Não foram encontrados nomes de companhias aéreas na coluna {coluna_airline_description} com números ou caracteres estranhos.\")\n",
        "else:\n",
        "    print(f\"Nomes de companhias aéreas na coluna {coluna_airline_description} com números ou caracteres estranhos.\")\n",
        "    print(linhas_fora_de_escopo_airline_description)\n",
        "\n",
        "#Verificar se a coluna FL_DATE possui somente datas.\n",
        "coluna_fl_date = 'FL_DATE'\n",
        "linhas_fora_de_escopo_fl_date = df_principal[~df_principal[coluna_fl_date].astype(str).str.match(r'\\d{4}-\\d{2}-\\d{2}', na=False)]\n",
        "if linhas_fora_de_escopo_fl_date.empty:\n",
        "    print(f\"Todas as entradas na coluna {coluna_fl_date} são datas válidas no formato DD-MM-YYYY.\")\n",
        "else:\n",
        "    print(f\"Entradas na coluna {coluna_fl_date} que não são datas válidas no formato DD-MM-YYYY.\")\n",
        "    print(linhas_fora_de_escopo_fl_date)\n",
        "\n",
        "#Verificar se a coluna DOT_CODE possui exatamente 5 números\n",
        "coluna_dot_code = 'DOT_CODE'\n",
        "linhas_fora_de_escopo_dot_code = df_principal[~df_principal[coluna_dot_code].apply(lambda x: len(str(x)) == 5 and str(x).isdigit())]\n",
        "if linhas_fora_de_escopo_dot_code.empty:\n",
        "    print(f\"Todas as linhas na coluna {coluna_dot_code} possuem 5 caracteres.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_dot_code} possuem caracteres diferentes de 5.\")\n",
        "    print(linhas_fora_de_escopo_dot_code)\n",
        "\n",
        "#Verificar se a coluna ORIGIN possui exatamente 3 letras\n",
        "coluna_origin = 'ORIGIN'\n",
        "linhas_fora_de_escopo_origin = df_principal[coluna_origin].astype(str).str.strip().apply(len) == 3\n",
        "if linhas_fora_de_escopo_origin.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_origin} possuem 3 letras.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_origin} não possuem 3 letras.\")\n",
        "    print(linhas_fora_de_escopo_origin)\n",
        "\n",
        "#Verificar se a coluna ORIGIN_CITY não possui números ou outros caracteres\n",
        "coluna_origin_city = 'ORIGIN_CITY'\n",
        "linhas_fora_de_escopo_origin_city = df_principal[coluna_origin_city].astype(str).apply(lambda x: all(letra.isalpha() or letra == ',' or letra == ' ' or letra == '/' or letra == '.' or letra == '-' for letra in x))\n",
        "if linhas_fora_de_escopo_origin_city.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_origin_city} contêm apenas letras e não contêm números ou caracteres especiais.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_origin_city} não contém apenas letras ou contém números/caracteres especiais.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_origin_city])\n",
        "\n",
        "#Verificar se a coluna DEST possui exatamente 3 letras\n",
        "coluna_dest = 'DEST'\n",
        "linhas_fora_de_escopo_dest = df_principal[coluna_dest].astype(str).str.strip().apply(len) == 3\n",
        "if linhas_fora_de_escopo_dest.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_dest} possuem 3 letras.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_dest} não possuem 3 letras.\")\n",
        "    print(linhas_fora_de_escopo_dest)\n",
        "\n",
        "#Verificar se a coluna DEST_CITY não possui números ou outros caracteres\n",
        "coluna_dest_city = 'DEST_CITY'\n",
        "linhas_fora_de_escopo_dest_city = df_principal[coluna_dest_city].astype(str).apply(lambda x: all(letra.isalpha() or letra == ',' or letra == ' ' or letra == '/' or letra == '.' or letra == '-' for letra in x))\n",
        "if linhas_fora_de_escopo_dest_city.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_dest_city} contêm apenas letras e não contêm números ou caracteres especiais.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_dest_city} não contém apenas letras ou contém números/caracteres especiais.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_dest_city])\n",
        "\n",
        "\n",
        "# Verificar se a coluna TAXI_OUT possui somente números\n",
        "#como taxi_out é float, foi necessário mudar para integer para verificar as informação de horário. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['TAXI_OUT'] = pd.to_numeric(df_principal['TAXI_OUT'], errors='coerce').astype(pd.Int32Dtype())\n",
        "coluna_taxi_out = 'TAXI_OUT'\n",
        "linhas_fora_de_escopo_taxi_out = df_principal[coluna_taxi_out].astype(str).str.match(r'^-?\\d+$')\n",
        "if linhas_fora_de_escopo_taxi_out.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_taxi_out} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_taxi_out} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_taxi_out])\n",
        "\n",
        "# Verificar se a coluna WHEELS_OFF possui até 4 números (variável de hora - 00:00)\n",
        "#como wheels_off é float, foi necessário mudar para integer para verificar as informação de horário. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['WHEELS_OFF'] = pd.to_numeric(df_principal['WHEELS_OFF'], errors='coerce').astype(pd.Int32Dtype())\n",
        "coluna_wheels_off = 'WHEELS_OFF'\n",
        "linhas_fora_de_escopo_wheels_off = df_principal[coluna_wheels_off].astype(str).str.strip().str.match(r'^\\d{1,4}$')\n",
        "if linhas_fora_de_escopo_wheels_off.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_wheels_off} possuem até 4 números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_wheels_off} não possuem até 4 números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_wheels_off])\n",
        "\n",
        "# Verificar se a coluna WHEELS_ON possui até 4 números (variável de hora - 00:00)\n",
        "#como wheels_on é float, foi necessário mudar para integer para verificar as informação de horário. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['WHEELS_ON'] = pd.to_numeric(df_principal['WHEELS_ON'], errors='coerce').astype(pd.Int32Dtype())\n",
        "coluna_wheels_on = 'WHEELS_ON'\n",
        "linhas_fora_de_escopo_wheels_on = df_principal[coluna_wheels_on].astype(str).str.strip().str.match(r'^\\d{1,4}$')\n",
        "if linhas_fora_de_escopo_wheels_on.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_wheels_on} possuem até 4 números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_wheels_on} não possuem até 4 números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_wheels_on])\n",
        "\n",
        "# Verificar se a coluna TAXI_IN possui somente números\n",
        "#como taxi_in é float, foi necessário mudar para integer para verificar as informação de horário. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['TAXI_IN'] = pd.to_numeric(df_principal['TAXI_IN'], errors='coerce').astype(pd.Int32Dtype())\n",
        "coluna_taxi_in = 'TAXI_IN'\n",
        "linhas_fora_de_escopo_taxi_in = df_principal[coluna_taxi_in].astype(str).str.match(r'^-?\\d+$')\n",
        "if linhas_fora_de_escopo_taxi_in.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_taxi_in} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_taxi_in} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_taxi_in])\n",
        "\n",
        "# Verificar se a coluna CRS_ARR_TIME possui até 4 números (variável de hora - 00:00)\n",
        "coluna_crs_arr_time = 'CRS_ARR_TIME'\n",
        "linhas_fora_de_escopo_crs_arr_time = df_principal[coluna_crs_arr_time].astype(str).str.strip().str.match(r'^\\d{1,4}$')\n",
        "if linhas_fora_de_escopo_crs_arr_time.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_crs_arr_time} possuem até 4 números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_crs_arr_time} não possuem até 4 números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_crs_arr_time])\n",
        "\n",
        "# Verificar se a coluna ARR_DELAY possui somente números\n",
        "#como arr_delay é float, foi necessário mudar para integer para verificar as informação de horário. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['ARR_DELAY'] = pd.to_numeric(df_principal['ARR_DELAY'], errors='coerce').astype(pd.Int32Dtype())\n",
        "coluna_arr_delay = 'ARR_DELAY'\n",
        "linhas_fora_de_escopo_arr_delay = df_principal['ARR_DELAY'].astype(str).str.match(r'^-?\\d+$')\n",
        "if linhas_fora_de_escopo_arr_delay.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_arr_delay} somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_arr_delay} não somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_arr_delay])\n",
        "\n",
        "#Verificar se a coluna CANCELLED e DIVERTED possuem exatamente 1 número\n",
        "coluna_cancelled = 'CANCELLED'\n",
        "coluna_diverted =  'DIVERTED'\n",
        "linhas_fora_de_escopo_cancelled = df_principal[coluna_cancelled].astype(str).str.strip().apply(len) == 1\n",
        "linhas_fora_de_escopo_diverted = df_principal[coluna_diverted].astype(str).str.strip().apply(len) == 1\n",
        "if linhas_fora_de_escopo_cancelled.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_cancelled} possui 1 número.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_cancelled} não possui 1 número.\")\n",
        "    print(linhas_fora_de_escopo_cancelled)\n",
        "if linhas_fora_de_escopo_diverted.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_diverted} possui 1 número.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_diverted} não possui 1 número.\")\n",
        "    print(linhas_fora_de_escopo_diverted)\n",
        "\n",
        "# Verificar se a coluna CANCELLATION_CODE possui exatamente 1 letra\n",
        "coluna_cancellation_code = 'CANCELLATION_CODE'\n",
        "linhas_fora_de_escopo_cancellation_code = df_principal[coluna_cancellation_code].astype(str).str.strip().apply(len) != 1\n",
        "\n",
        "if linhas_fora_de_escopo_cancellation_code.any():\n",
        "    print(f\"Linhas onde a coluna {coluna_cancellation_code} não possui 1 letra.\")\n",
        "    print(df_principal[linhas_fora_de_escopo_cancellation_code])\n",
        "else:\n",
        "    print(f\"Todas as linhas na coluna {coluna_cancellation_code} possuem exatamente 1 letra.\")\n",
        "\n",
        "# Verificar se a coluna CRS_ELAPSED_TIME possui números\n",
        "#como CRS_ELAPSED_TIME é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['CRS_ELAPSED_TIME'] = pd.to_numeric(df_principal['CRS_ELAPSED_TIME'], errors='coerce')\n",
        "coluna_crs_elapsed_time = 'CRS_ELAPSED_TIME'\n",
        "linhas_fora_de_escopo_crs_elapsed_time =linhas_validas = df_principal[coluna_crs_elapsed_time].apply(lambda x: pd.isna(x) or isinstance(x, (int, float)))\n",
        "if linhas_fora_de_escopo_crs_elapsed_time.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_crs_elapsed_time} possuem até 4 números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_crs_elapsed_time} não possuem até 4 números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_crs_elapsed_time])\n",
        "\n",
        "# Verificar se a coluna ELAPSED_TIME possui somente números\n",
        "#como ELAPSED_TIME é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['ELAPSED_TIME'] = df_principal['ELAPSED_TIME'] = pd.to_numeric(df_principal['ELAPSED_TIME'], errors='coerce')\n",
        "coluna_elapsed_time = 'ELAPSED_TIME'\n",
        "linhas_fora_de_escopo_elapsed_time = df_principal[coluna_elapsed_time].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_elapsed_time]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_elapsed_time} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_elapsed_time} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_elapsed_time])\n",
        "\n",
        "# Verificar se a coluna AIR_TIME possui somente números\n",
        "#como AIR_TIME é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['AIR_TIME'] = df_principal['AIR_TIME'] = pd.to_numeric(df_principal['AIR_TIME'], errors='coerce')\n",
        "coluna_air_time = 'AIR_TIME'\n",
        "linhas_fora_de_escopo_air_time = df_principal[coluna_air_time].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_air_time]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_air_time} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_air_time} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_air_time])\n",
        "\n",
        "# Verificar se a coluna DISTANCE possui somente números\n",
        "df_principal['DISTANCE'] = df_principal['DISTANCE'] = pd.to_numeric(df_principal['DISTANCE'], errors='coerce')\n",
        "coluna_distance = 'DISTANCE'\n",
        "linhas_fora_de_escopo_distance = df_principal[coluna_distance].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_distance]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_distance} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_distance} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_distance])\n",
        "\n",
        "# Verificar se a coluna DELAY_DUE_CARRIER possui somente números\n",
        "#como DELAY_DUE_CARRIER é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['DELAY_DUE_CARRIER'] = df_principal['DELAY_DUE_CARRIER'] = pd.to_numeric(df_principal['DELAY_DUE_CARRIER'], errors='coerce')\n",
        "coluna_delay_due_carrier = 'DELAY_DUE_CARRIER'\n",
        "linhas_fora_de_escopo_delay_due_carrier = df_principal[coluna_delay_due_carrier].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_delay_due_carrier]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_delay_due_carrier} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_delay_due_carrier} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_delay_due_carrier])\n",
        "\n",
        "# Verificar se a coluna DELAY_DUE_WEATHER possui somente números\n",
        "#como DELAY_DUE_WEATHER é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['DELAY_DUE_WEATHER'] = df_principal['DELAY_DUE_WEATHER'] = pd.to_numeric(df_principal['DELAY_DUE_WEATHER'], errors='coerce')\n",
        "coluna_delay_due_weather = 'DELAY_DUE_WEATHER'\n",
        "linhas_fora_de_escopo_delay_due_weather = df_principal[coluna_delay_due_weather].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_delay_due_weather]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_delay_due_weather} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_delay_due_weather} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_delay_due_weather])\n",
        "\n",
        "# Verificar se a coluna DELAY_DUE_NAS possui somente números\n",
        "#como DELAY_DUE_NAS é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['DELAY_DUE_NAS'] = df_principal['DELAY_DUE_NAS'] = pd.to_numeric(df_principal['DELAY_DUE_NAS'], errors='coerce')\n",
        "coluna_delay_due_nas = 'DELAY_DUE_NAS'\n",
        "linhas_fora_de_escopo_delay_due_nas = df_principal[coluna_delay_due_nas].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_delay_due_nas]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_delay_due_nas} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_delay_due_nas} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_delay_due_nas])\n",
        "\n",
        "# Verificar se a coluna DELAY_DUE_SECURITY possui somente números\n",
        "#como DELAY_DUE_SECURITY é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['DELAY_DUE_SECURITY'] = df_principal['DELAY_DUE_SECURITY'] = pd.to_numeric(df_principal['DELAY_DUE_SECURITY'], errors='coerce')\n",
        "coluna_delay_due_security = 'DELAY_DUE_SECURITY'\n",
        "linhas_fora_de_escopo_delay_due_security = df_principal[coluna_delay_due_security].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_delay_due_security]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_delay_due_security} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_delay_due_security} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_delay_due_security])\n",
        "\n",
        "# Verificar se a coluna DELAY_DUE_LATE_AIRCRAFT possui somente números\n",
        "#como DELAY_DUE_LATE_AIRCRAFT é float, foi necessário mudar para integer para verificar as informação de atrasos. O código ignora os nulos, pois os nulos serão importantes para as avaliaçoes futuras.\n",
        "df_principal['DELAY_DUE_LATE_AIRCRAFT'] = df_principal['DELAY_DUE_LATE_AIRCRAFT'] = pd.to_numeric(df_principal['DELAY_DUE_LATE_AIRCRAFT'], errors='coerce')\n",
        "coluna_delay_due_late_aircraft = 'DELAY_DUE_LATE_AIRCRAFT'\n",
        "linhas_fora_de_escopo_delay_due_late_aircraft = df_principal[coluna_delay_due_late_aircraft].astype(str).str.match(r'^-?\\d+$')\n",
        "if pd.api.types.is_numeric_dtype(df_principal[coluna_delay_due_late_aircraft]):\n",
        "    print(f\"Todas as linhas na coluna {coluna_delay_due_late_aircraft} possuem somente números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_delay_due_late_aircraft} não possuem somente números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_delay_due_late_aircraft])\n",
        "\n",
        "# Verificar se a coluna FL_YEAR possui até 4 números\n",
        "coluna_fl_year = 'FL_YEAR'\n",
        "linhas_fora_de_escopo_fl_year = df_principal[coluna_fl_year].astype(str).str.strip().str.match(r'^\\d{1,4}$')\n",
        "if linhas_fora_de_escopo_fl_year.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_fl_year} possuem até 4 números.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_fl_year} não possuem até 4 números.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_fl_year])\n",
        "\n",
        "# Verificar se a coluna FL_MONTH possui números de 1 a 12 (referente aos meses)\n",
        "coluna_fl_month = 'FL_MONTH'\n",
        "linhas_fora_de_escopo_fl_month = df_principal[coluna_fl_month].astype(str).str.strip().str.match(r'^\\d{1,12}$')\n",
        "if linhas_fora_de_escopo_fl_month.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_fl_month} possui número entre 1 e 12.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_fl_month} não possui número entre 1 e 12.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_fl_month])\n",
        "\n",
        "# Verificar se a coluna FL_DAY possui números entre 1 e 31 (referente ao número de dias do mês)\n",
        "coluna_fl_day = 'FL_DAY'\n",
        "linhas_fora_de_escopo_fl_day = df_principal[coluna_fl_day].astype(str).str.strip().str.match(r'^\\d{1,31}$')\n",
        "if linhas_fora_de_escopo_fl_day.all():\n",
        "    print(f\"Todas as linhas na coluna {coluna_fl_day} possui número entre 1 e 31.\")\n",
        "else:\n",
        "    print(f\"Linhas onde a coluna {coluna_fl_day} não possui número entre 1 e 31.\")\n",
        "    print(df_principal[~linhas_fora_de_escopo_fl_day])\n"
      ],
      "metadata": {
        "id": "kco3EeE5_5QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizar os dados limpos e realizar buscas"
      ],
      "metadata": {
        "id": "EAjxeM7Y2JVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo possibilita a pesquisa dentro do banco de dados limpo e organizado."
      ],
      "metadata": {
        "id": "FH88q3Rq2uSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações de exibição do pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "# Função para mostrar a tabela\n",
        "def show_table(page_number, df_principal):\n",
        "    start_idx = (page_number - 1) * 10\n",
        "    end_idx = start_idx + 10\n",
        "    display(df_principal.iloc[start_idx:end_idx])\n",
        "\n",
        "# Função para atualizar a tabela com base na página selecionada\n",
        "def on_page_change(change):\n",
        "    show_table(change['new'], df_filtered)\n",
        "\n",
        "# Função para buscar por um valor específico em uma coluna\n",
        "def on_search_clicked(b):\n",
        "    global df_filtered\n",
        "    column = column_selector.value\n",
        "    value = value_input.value\n",
        "    if column in df_principal.columns:\n",
        "        # Convert the string value to a list for isin()\n",
        "        df_filtered = df_principal[df_principal[column].astype(str).isin([value])]  # Wrap value in a list\n",
        "    else:\n",
        "        df_filtered = df_principal\n",
        "\n",
        "    page_selector.max = len(df_filtered) // 10 + 1\n",
        "    page_selector.value = 1  # Resetar para a primeira página\n",
        "    show_table(1, df_filtered)\n",
        "\n",
        "# Inicialmente, exibe todas as linhas\n",
        "df_filtered = df_principal\n",
        "\n",
        "# Função para atualizar as opções de dados com base na coluna selecionada\n",
        "def on_column_change(change):\n",
        "    column = change['new']\n",
        "    unique_values = df_principal[column].unique().tolist()\n",
        "\n",
        "\n",
        "# Widgets para buscar por um dado específico\n",
        "column_selector = widgets.Dropdown(description='Coluna:', options=df_principal.columns.tolist())\n",
        "value_input = widgets.Text(description='Valor:')\n",
        "search_button = widgets.Button(description='Buscar')\n",
        "\n",
        "# Adiciona a funcionalidade ao botão de busca\n",
        "search_button.on_click(on_search_clicked)\n",
        "\n",
        "# Atualiza as opções de dados quando a coluna é alterada\n",
        "column_selector.observe(on_column_change, names='value')\n",
        "\n",
        "# Widget para selecionar a página\n",
        "page_selector = widgets.IntSlider(min=1, max=len(df_principal) // 10 + 1, description='Página')\n",
        "page_selector.observe(on_page_change, names='value')\n",
        "\n",
        "\n",
        "# Exibe os widgets de busca e a tabela inicial\n",
        "search_widgets_ui = widgets.VBox([column_selector, value_input, search_button])\n",
        "display(search_widgets_ui)\n",
        "widgets_ui = widgets.VBox([page_selector])\n",
        "display(widgets_ui)\n",
        "show_table(1, df_filtered)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4SKyaqXC2nlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Análise exploratória\n",
        "\n",
        "O objetivo desta sessão é identificar padrões, tendências e fatores que contribuem para os eventos de atrasos e cancelamentos de voos, fornecendo informações valiosas para a tomada de decisões e melhoria da eficiência do sistema de transporte aéreo."
      ],
      "metadata": {
        "id": "wzGE4SxcJlMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Medidas de tendência central"
      ],
      "metadata": {
        "id": "11gMzr3MAilv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A primeira análise de medidas de tendência central foram das colunas DEP_DELAY', 'ARR_DELAY','ELAPSED_TIME' e 'DISTANCE'.\n",
        "\n",
        "Estas informações foram escolhidas por apresentarem registros gerais, contendo desde voos atrasados e no horário."
      ],
      "metadata": {
        "id": "r_vwkayrA6GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisando informações de atraso de todos os voos\n",
        "resumo = df_principal[['DEP_DELAY', 'ARR_DELAY','ELAPSED_TIME', 'DISTANCE']].describe(include='all')\n",
        "\n",
        "# Exibir o resumo\n",
        "display(resumo)"
      ],
      "metadata": {
        "id": "RZ6_hK_PAvKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliando as medidas, podemos perceber que a mediana (50%) é relativa a voos que partem e chegam no horário e com distância de 1093 quilometros.\n",
        "\n",
        "Entretanto, para avaliarmos os voos atrasados, foco deste estudo, é necessário ir mais a fundo."
      ],
      "metadata": {
        "id": "xUM04l7LDsBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame onde DELAYED_DUMMY é igual a 1\n",
        "df_filtered = df_principal[df_principal['DELAYED_DUMMY'] == 1]\n",
        "\n",
        "# Selecionar as colunas desejadas e aplicar describe\n",
        "resumo = df_filtered[['DEP_DELAY', 'ARR_DELAY']].describe(include='all')\n",
        "\n",
        "# Exibir o resumo\n",
        "display(resumo)"
      ],
      "metadata": {
        "id": "z_DXgsYcB1h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A média de atrasado é de 42min, entretanto a média é puxada para a direita por causa dos outliers. Para uma analise mais justa é interessante estudar a mediana. A mediana neste caso é de 18 min de atraso. Podemos infererir que mesmo que ocorram atrasos estes geralmente são curtos. Atrasos maiores de 1h estão presentes somente a partir do quartil 4, sendo menos de 25% dos casos de atraso.\n",
        "\n"
      ],
      "metadata": {
        "id": "sgXA3al0EW_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dos casos atrasados analisados, 50,31% não possuem motivo cadastrado. Por isso, muitos valores referentes a motivos de atraso não foram analisados em conjunto. Abaixo foi realizado uma análise referente aos valores cadastrados como motivo."
      ],
      "metadata": {
        "id": "qSwiwNv46DyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame onde DELAYED_DUMMY é igual a 1\n",
        "df_filtered = df_principal[df_principal['DELAY_DUE_CARRIER'] > 1]\n",
        "\n",
        "# Selecionar as colunas desejadas e aplicar describe\n",
        "resumo = df_filtered[['DEP_DELAY', 'ARR_DELAY', 'DELAY_DUE_CARRIER']].describe(include='all')\n",
        "\n",
        "# Exibir o resumo\n",
        "display(resumo)"
      ],
      "metadata": {
        "id": "xR_9qxRpF0dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coluna relativo a delay_due_carrier é referente ao atraso da companhia aerea. A mediana nesse caso é de 21 min, onde podemos inferir que são poucos os atrasos que ultrapassam de 1 hora em caso de organização da companhia aérea."
      ],
      "metadata": {
        "id": "w58Wjf-pHhVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame onde DELAYED_DUMMY é igual a 1\n",
        "df_filtered = df_principal[df_principal['DELAY_DUE_WEATHER'] > 1]\n",
        "\n",
        "# Selecionar as colunas desejadas e aplicar describe\n",
        "resumo = df_filtered[['DEP_DELAY', 'ARR_DELAY', 'DELAY_DUE_WEATHER']].describe(include='all')\n",
        "\n",
        "# Exibir o resumo\n",
        "display(resumo)"
      ],
      "metadata": {
        "id": "fYKaW_E4H99B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coluna delay_due_weather é referente ao atraso por causa do clima. A mediana nesse caso é de 35 min, e sua máxima de 1653min. A média é alta por causa dos outilers, não sendo assertiva para esta análise."
      ],
      "metadata": {
        "id": "5RRJVgraIIre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame onde DELAYED_DUMMY é igual a 1\n",
        "df_filtered = df_principal[df_principal['DELAY_DUE_NAS'] > 1]\n",
        "\n",
        "# Selecionar as colunas desejadas e aplicar describe\n",
        "resumo = df_filtered[['DEP_DELAY', 'ARR_DELAY', 'DELAY_DUE_NAS']].describe(include='all')\n",
        "\n",
        "# Exibir o resumo\n",
        "display(resumo)"
      ],
      "metadata": {
        "id": "l8pF9jKMIu6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coluna relativo a delay_due_nas é referente ao atraso por causa do sistema de tráfego aéreo. A mediana nesse caso é de 19 min, e sua máxima de 1343min. A média é alta por causa dos outilers, não sendo assertiva para esta análise. Neste caso podemos inferir que atrasos devido ao sistma ocorrem, porém na grande maioria dos casos é menos de 33 minutos."
      ],
      "metadata": {
        "id": "vtGhBoaXI6Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame onde DELAYED_DUMMY é igual a 1\n",
        "df_filtered = df_principal[df_principal['DELAY_DUE_SECURITY'] > 1]\n",
        "\n",
        "# Selecionar as colunas desejadas e aplicar describe\n",
        "resumo = df_filtered[['DEP_DELAY', 'ARR_DELAY', 'DELAY_DUE_SECURITY']].describe(include='all')\n",
        "\n",
        "# Exibir o resumo\n",
        "display(resumo)"
      ],
      "metadata": {
        "id": "RZ2wIGETJRS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coluna relativo a delay_due_security é referente ao atraso por causa de segurança. A mediana nesse caso é de 19 min, e sua máxima de 234min. A média é alta por causa dos outilers, não sendo assertiva para esta análise. Neste caso podemos inferir que atrasos devido a segurança ocorrem, porém na grande maioria dos casos é menos de 33 minutos."
      ],
      "metadata": {
        "id": "wQMHiIi6JcGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame onde DELAYED_DUMMY é igual a 1\n",
        "df_filtered = df_principal[df_principal['DELAY_DUE_LATE_AIRCRAFT'] > 1]\n",
        "\n",
        "# Selecionar as colunas desejadas e aplicar describe\n",
        "resumo = df_filtered[['DEP_DELAY', 'ARR_DELAY', 'DELAY_DUE_LATE_AIRCRAFT']].describe(include='all')\n",
        "\n",
        "\n",
        "# Exibir o resumo\n",
        "display(resumo)"
      ],
      "metadata": {
        "id": "pdtIdZ_vJptu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coluna relativo a delay_due_late_aircraft é referente ao atraso por causa de avião atrasado. A mediana nesse caso é de 33 min, e sua máxima de 2027min. A média é alta por causa dos outilers, não sendo assertiva para esta análise. Neste caso podemos inferir que atrasos devido a aviões atrasados ocorrem, porém na grande maioria dos casos é menos de 1 hora e 10."
      ],
      "metadata": {
        "id": "g332a2RvLAR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar o DataFrame para incluir apenas as linhas onde cancelados == 1\n",
        "df_cancelados = df_principal[df_principal['CANCELLED'] == 1]\n",
        "\n",
        "# Selecionar as colunas desejadas e aplicar describe\n",
        "descricao = df_cancelados[['DEP_DELAY', 'DISTANCE']].describe(include='all')\n",
        "\n",
        "# Exibir a descrição\n",
        "display(descricao)"
      ],
      "metadata": {
        "id": "di9caYzQLsc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referente aos voos cancelados, a coluna DEP_DELAY não nos informa muito, visto que o voo não decolou. Entretanto é possível perceber o tempo que os passageiros esperaram até receber a notícia.  Referente a distancia, é possível perceber que não existe um padrão. Tanto voos curtos quanto distantes foram passíveis de cancelamento em janeiro de 2023."
      ],
      "metadata": {
        "id": "ukyoGiZ-Mhgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo é possível ver a relação de voos diários em janeiro de 2023 por companhia aérea. As 5 companhias aéreas com mais voos neste período foram:\n",
        "\n",
        "*   Southwest Airlines Co.\n",
        "*   American Airlines Inc.\n",
        "*   Delta Air Lines Inc.\n",
        "*   SkyWest Airlines Inc.\n",
        "*   United Air Lines Inc.\n",
        "\n"
      ],
      "metadata": {
        "id": "anU77GTsOqH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a coluna 'data' para tipo datetime se necessário\n",
        "df_principal['FL_DATE'] = pd.to_datetime(df_principal['FL_DATE'])\n",
        "\n",
        "# Agrupar por data e companhia e contar o número de voos\n",
        "voos_por_dia = df_principal.groupby([df_principal['FL_DATE'].dt.day, 'AIRLINE_DESCRIPTION']).size().unstack()\n",
        "\n",
        "# Plotar o gráfico de linhas\n",
        "ax = voos_por_dia.plot(kind='line', figsize=(15, 10))\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.title('Quantidade de Voos por Companhia Aérea - Janeiro 2023')\n",
        "plt.xlabel('Dia do Mês')\n",
        "plt.ylabel('Quantidade de Voos')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Adicionar nome da companhia ao lado de cada linha\n",
        "for line, label in zip(ax.lines, voos_por_dia.columns):\n",
        "    y = line.get_ydata()[-1]  # Posição y do final da linha\n",
        "    ax.annotate(label, xy=(1, y), xytext=(6, 0), color=line.get_color(),\n",
        "                xycoords=('axes fraction', 'data'), textcoords='offset points',\n",
        "                size=12, va='center')\n",
        "\n",
        "# Definir todos os dias do mês como rótulos no eixo x\n",
        "dias_do_mes = voos_por_dia.index\n",
        "plt.xticks(range(len(dias_do_mes)), range(len(dias_do_mes)))\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.legend().remove()\n",
        "plt.tight_layout()  # Ajusta o layout para evitar cortes\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fZXDwBhJOOCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quantidade de voos varia por dia. O código abaixo nos permite analisar melhor:"
      ],
      "metadata": {
        "id": "_U1Fj5O9QEt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar por data e contar o número de voos\n",
        "voos_por_dia = df_principal.groupby('FL_DATE').size().reset_index(name='NUM_VOOS')\n",
        "\n",
        "# Encontrar o dia com o maior número de voos\n",
        "dia_mais_voos = voos_por_dia.loc[voos_por_dia['NUM_VOOS'].idxmax()]\n",
        "\n",
        "# Calcular a média de voos por dia\n",
        "media_voos_por_dia = voos_por_dia['NUM_VOOS'].mean()\n",
        "\n",
        "# Encontrar o dia com o menor número de voos\n",
        "dia_menos_voos = voos_por_dia.loc[voos_por_dia['NUM_VOOS'].idxmin()]\n",
        "\n",
        "print(\"Dia com menos voos:\")\n",
        "display(dia_menos_voos)\n",
        "\n",
        "display(f\"Média de voos por dia: {media_voos_por_dia:.2f}\")\n",
        "\n",
        "print(\"Dia com mais voos:\")\n",
        "display(dia_mais_voos)"
      ],
      "metadata": {
        "id": "J6d_eqz6Pmlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dia com menos voos foi 14/01/2023 com 14.818 voos.\n",
        "- Dia com mais voos foi 27/01/2023 com 18.539 voos.\n",
        "- A média de voos em janeiro de 2023 nos EUA ficou em 17.381 voos diários."
      ],
      "metadata": {
        "id": "JEn_7FJDQOxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gráfico de voos atrasados em janeiro de 2023 por companhia aérea."
      ],
      "metadata": {
        "id": "zGZfy_T4RGpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a coluna 'data' para tipo datetime se necessário\n",
        "df_principal['FL_DATE'] = pd.to_datetime(df_principal['FL_DATE'])\n",
        "\n",
        "# Filtrar apenas voos atrasados\n",
        "df_delayed = df_principal[df_principal['DELAYED_DUMMY'] == 1]\n",
        "\n",
        "# Agrupar por data e companhia e contar o número de voos atrasados\n",
        "voos_atrasados_por_dia = df_delayed.groupby([df_delayed['FL_DATE'].dt.day, 'AIRLINE_DESCRIPTION']).size().unstack()\n",
        "\n",
        "# Plotar o gráfico de linhas\n",
        "ax = voos_atrasados_por_dia.plot(kind='line', figsize=(15, 10))\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.title('Quantidade de Voos Atrasados por Companhia Aérea - Janeiro 2023')\n",
        "plt.xlabel('Dia do Mês')\n",
        "plt.ylabel('Quantidade de Voos Atrasados')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Adicionar nome da companhia ao lado de cada linha\n",
        "for line, label in zip(ax.lines, voos_atrasados_por_dia.columns):\n",
        "    y = line.get_ydata()[-1]  # Posição y do final da linha\n",
        "    ax.annotate(label, xy=(1, y), xytext=(6, 0), color=line.get_color(),\n",
        "                xycoords=('axes fraction', 'data'), textcoords='offset points',\n",
        "                size=12, va='center')\n",
        "\n",
        "# Definir todos os dias do mês como rótulos no eixo x\n",
        "dias_do_mes_atrasados = voos_atrasados_por_dia.index\n",
        "plt.xticks(range(len(dias_do_mes_atrasados)), range(len(dias_do_mes_atrasados)))\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.legend().remove()\n",
        "plt.tight_layout()  # Ajusta o layout para evitar cortes\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4xPqZiVzQ76x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em valores absolutos, as companhias com mais recorrencia de voos atrasados são:\n",
        "- Southwest Airlines Co.\n",
        "- Delta Air Lines Inc.\n",
        "- American Airlines Inc.\n",
        "- United Air Lines Inc.\n",
        "- SkyWest Airlines Inc.\n"
      ],
      "metadata": {
        "id": "EtQfGhDLROpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo foi realizado uma análise de voos cancelados. No gráfico abaixo é possível ver a quantidade de voos cancelados por dia, segmentados por companhia aérea."
      ],
      "metadata": {
        "id": "uY7vhXA0R4fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir uma paleta de 15 cores distintas\n",
        "colors = [\n",
        "    '#8B0000', '#006400', '#4363d8', '#00008B', '#FF8C00',\n",
        "    '#4B0082', '#40E0D0', '#EE82EE', '#808000', '#DC143C',\n",
        "    '#2E8B57', '#6A5ACD', '#D2691E', '#FF7F50', '#2F4F4F'\n",
        "]\n",
        "\n",
        "# Converter a coluna 'data' para tipo datetime se necessário\n",
        "df_principal['FL_DATE'] = pd.to_datetime(df_principal['FL_DATE'])\n",
        "\n",
        "# Filtrar apenas voos cancelados\n",
        "df_delayed = df_principal[df_principal['CANCELLED'] == 1]\n",
        "\n",
        "# Agrupar por data e companhia e contar o número de voos cancelados\n",
        "voos_cancelados_por_dia = df_delayed.groupby([df_delayed['FL_DATE'].dt.day, 'AIRLINE_DESCRIPTION']).size().unstack()\n",
        "\n",
        "# Plotar o gráfico de barras empilhadas com cores personalizadas\n",
        "ax = voos_cancelados_por_dia.plot(kind='bar', figsize=(15, 10), stacked=True, color=colors)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.title('Quantidade de voos cancelados por Companhia Aérea - Janeiro 2023')\n",
        "plt.xlabel('Dia do Mês')\n",
        "plt.ylabel('Quantidade de Voos cancelados')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Adicionar nome da companhia ao lado de cada linha\n",
        "for line, label in zip(ax.lines, voos_cancelados_por_dia.columns):\n",
        "    y = line.get_ydata()[-1]  # Posição y do final da linha\n",
        "    ax.annotate(label, xy=(1, y), xytext=(6, 0), color=line.get_color(),\n",
        "                xycoords=('axes fraction', 'data'), textcoords='offset points',\n",
        "                size=12, va='center')\n",
        "\n",
        "# Definir todos os dias do mês como rótulos no eixo x\n",
        "dias_do_mes_cancelados = voos_cancelados_por_dia.index\n",
        "plt.xticks(range(len(dias_do_mes_cancelados)), [dia + 1 for dia in range(len(dias_do_mes_cancelados))])\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.legend()\n",
        "plt.tight_layout()  # Ajusta o layout para evitar cortes\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iv_Az6QwUSYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível perceber que os dias com mais cancelamentos foram o dia 31, 11 e 30 de janeiro de 2023. As companhias que mais operam acabam tendo mais voos cancelados. Para analisa-los é necessário calcular a taxa de cancelamento por companhia."
      ],
      "metadata": {
        "id": "4XDRQ5xAVULA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo foi realizado uma análise de voos desviados do destino final. No gráfico abaixo é possível ver a quantidade de voos desviados por dia, segmentados por companhia aérea."
      ],
      "metadata": {
        "id": "MSCkKdabWfEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir uma paleta de 15 cores distintas\n",
        "colors = [\n",
        "    '#8B0000', '#006400', '#4363d8', '#00008B', '#FF8C00',\n",
        "    '#4B0082', '#40E0D0', '#EE82EE', '#808000', '#DC143C',\n",
        "    '#2E8B57', '#6A5ACD', '#D2691E', '#FF7F50', '#2F4F4F'\n",
        "]\n",
        "\n",
        "# Converter a coluna 'data' para tipo datetime se necessário\n",
        "df_principal['FL_DATE'] = pd.to_datetime(df_principal['FL_DATE'])\n",
        "\n",
        "# Filtrar apenas voos desviados\n",
        "df_delayed = df_principal[df_principal['DIVERTED'] == 1]\n",
        "\n",
        "# Agrupar por data e companhia e contar o número de voos desviados\n",
        "voos_desviados_por_dia = df_delayed.groupby([df_delayed['FL_DATE'].dt.day, 'AIRLINE_DESCRIPTION']).size().unstack()\n",
        "\n",
        "# Plotar o gráfico de barras empilhadas com cores personalizadas\n",
        "ax = voos_desviados_por_dia.plot(kind='bar', figsize=(15, 10), stacked=True, color=colors)\n",
        "\n",
        "# Configurações do gráfico\n",
        "plt.title('Quantidade de voos desviados por Companhia Aérea - Janeiro 2023')\n",
        "plt.xlabel('Dia do Mês')\n",
        "plt.ylabel('Quantidade de Voos desviados')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Adicionar nome da companhia ao lado de cada linha\n",
        "for line, label in zip(ax.lines, voos_desviados_por_dia.columns):\n",
        "    y = line.get_ydata()[-1]  # Posição y do final da linha\n",
        "    ax.annotate(label, xy=(1, y), xytext=(6, 0), color=line.get_color(),\n",
        "                xycoords=('axes fraction', 'data'), textcoords='offset points',\n",
        "                size=12, va='center')\n",
        "\n",
        "# Definir todos os dias do mês como rótulos no eixo x\n",
        "dias_do_mes_desviados = voos_desviados_por_dia.index\n",
        "plt.xticks(range(len(dias_do_mes_desviados)), [dia + 1 for dia in range(len(dias_do_mes_desviados))])\n",
        "\n",
        "# Mostrar o gráfico\n",
        "plt.legend()\n",
        "plt.tight_layout()  # Ajusta o layout para evitar cortes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OSLQRqf_WA-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível perceber que os dias com mais voos deviados foram os dias 02, 03 e 01 de janeiro de 2023. As companhias que mais operam acabam tendo mais voos desviados. Para analisá-los é necessário calcular a taxa de desvio por companhia."
      ],
      "metadata": {
        "id": "g4VFiku6YbaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para analisar o clima e sua relação com cancelados, desviados e atrasados realizamos uma segmentação. Esta segmentação foi feita como GOOD (bom para voo), ACCEPTABLE (aceitável para operaçao de voo) e DANGEROUS (perigoso para operar voo). A classificação foi realizada por conveniência pelas analistas."
      ],
      "metadata": {
        "id": "2Lv8R55rZ0_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para categorizar o clima\n",
        "def categorize_climate(climate):\n",
        "    if climate in ['clear sky', 'few clouds', 'scattered clouds']:\n",
        "        return 'GOOD'\n",
        "    elif climate in ['broken clouds', 'light intensity drizzle', 'light rain', 'mist', 'moderate rain', 'overcast clouds', 'haze']:\n",
        "        return 'ACCEPTABLE'\n",
        "    elif climate in ['fog', 'heavy intensity rain', 'smoke', 'thunderstorm', 'thunderstorm with heavy rain', 'thunderstorm with light rain']:\n",
        "        return 'DANGEROUS'\n",
        "    else:\n",
        "        return 'UNKNOWN'\n",
        "\n",
        "# Aplicar a função para criar uma nova coluna 'CLIMATE_CATEGORY'\n",
        "df_principal['CLIMATE_CATEGORY'] = df_principal['CLIMATE'].apply(categorize_climate)\n",
        "\n",
        "# Criar colunas dummy\n",
        "df_principal = pd.concat([df_principal, pd.get_dummies(df_principal['CLIMATE_CATEGORY'], prefix='CLIMATE')], axis=1)"
      ],
      "metadata": {
        "id": "IVd2RQ9fZAWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupamos os dados por data e clima, e contamos as ocorrências\n",
        "df_agrupado = df_principal.groupby(['FL_DATE', 'CLIMATE_CATEGORY']).size().reset_index(name='count')\n",
        "\n",
        "# Criamos uma tabela pivot onde as colunas são os tipos de clima\n",
        "df_pivot = df_agrupado.pivot(index='FL_DATE', columns='CLIMATE_CATEGORY', values='count').fillna(0)\n",
        "\n",
        "# Mapeamos as cores para cada categoria de clima\n",
        "color_mapping = {\n",
        "    'ACCEPTABLE': 'orange',\n",
        "    'GOOD': 'green',\n",
        "    'DANGEROUS': 'red'\n",
        "}\n",
        "\n",
        "# Obtemos as cores na ordem das colunas do DataFrame pivot\n",
        "colors = [color_mapping[climate] for climate in df_pivot.columns]\n",
        "\n",
        "# Agora, criamos um gráfico de barras empilhadas utilizando pandas\n",
        "df_pivot.plot(kind='bar', stacked=True, figsize=(15, 10), color=colors)\n",
        "\n",
        "plt.title('Clima nas cidades em janeiro')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Quantidade de ocorrências')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Clima')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KzPUNGrMY3_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O grafico acima não revelou possíveis causas, visto que foi feito uma análise geral. Para gerar esclarecimentos é necessário avaliação mais robusta."
      ],
      "metadata": {
        "id": "Moq-VVnHaguN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo apresenta uma relação de quantidade de voo por aeroporto presente no banco de dados. São 339 aeroportos."
      ],
      "metadata": {
        "id": "ac2HncQDbD4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a coluna 'FL_DATE' para datetime\n",
        "df_principal['FL_DATE'] = pd.to_datetime(df_principal['FL_DATE'])\n",
        "\n",
        "# Agrupar por aeroporto e contar o número de voos\n",
        "voos_por_aeroporto = df_principal.groupby('ORIGIN').size()\n",
        "\n",
        "# Mostrar a tabela de quantidade de voos por aeroporto\n",
        "display(\"Tabela de Quantidade de Voos por Aeroporto - Janeiro 2023\")\n",
        "display(voos_por_aeroporto)"
      ],
      "metadata": {
        "id": "9-p1kQWpagfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar o número de voos por aeroporto\n",
        "contagem_voos = df_principal['ORIGIN'].value_counts()\n",
        "\n",
        "# Encontrar o aeroporto com menos voos\n",
        "aeroporto_com_menos_voos = contagem_voos.idxmin()\n",
        "menos_voos = contagem_voos.min()\n",
        "\n",
        "print(f\"Aeroporto com menos voos: {aeroporto_com_menos_voos} - {menos_voos} voos\")"
      ],
      "metadata": {
        "id": "pz1zzSpxbXE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O aeroporto com menos voos registrados é o Yellowstone Regional Airport, com 3 voos realizados no mês de janeiro de 2023."
      ],
      "metadata": {
        "id": "gHXmK8YdbbX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar o número de voos por aeroporto\n",
        "contagem_voos = df_principal['ORIGIN'].value_counts()\n",
        "\n",
        "# Encontrar o aeroporto com mais voos\n",
        "aeroporto_com_mais_voos = contagem_voos.idxmax()\n",
        "mais_voos = contagem_voos.max()\n",
        "\n",
        "print(f\"Aeroporto com mais voos: {aeroporto_com_mais_voos} - {mais_voos} voos\")"
      ],
      "metadata": {
        "id": "nWl969AyboWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O aeroporto com mais voos registrados é o Aeroporto Internacional de Atlanta Hartsfield-Jackson, com 26582 voos realizados no mês de janeiro de 2023."
      ],
      "metadata": {
        "id": "LqYAoAQkbvdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular média de voos por aeroporto\n",
        "media_voos_por_aeroporto = df_principal.groupby('ORIGIN').size().mean()\n",
        "\n",
        "print(f\"Média de voos por aeroporto: {media_voos_por_aeroporto:.2f}\")"
      ],
      "metadata": {
        "id": "43bvAjm-b4Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em média, foram realizados 1589 voos por mês por aeroporto nos EUA em janeiro de 2023. Importante ressaltar que existem aeroportos com muito fluxo e aeroportos com pouco fluxo, onde a média é mais utilizada para noção de tamanho do que capacidade/procura de cada aeroporto."
      ],
      "metadata": {
        "id": "B81jPgAAb8Ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Correlação entre as variáveis"
      ],
      "metadata": {
        "id": "w2cf_tV0g1N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionar as colunas para calcular a correlação\n",
        "columns = [\n",
        "    'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'WHEELS_OFF',\n",
        "    'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME', 'ARR_DELAY',\n",
        "    'CANCELLED', 'DIVERTED', 'CRS_ELAPSED_TIME', 'ELAPSED_TIME',\n",
        "    'AIR_TIME', 'DISTANCE', 'DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER',\n",
        "    'DELAY_DUE_NAS', 'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT',\n",
        "    'NATIONAL_HOLIDAY_DUMMY', 'DELAYED_DUMMY','CLIMATE_ACCEPTABLE',\t'CLIMATE_DANGEROUS',\t'CLIMATE_GOOD'\n",
        "]\n",
        "\n",
        "# Calcular a matriz de correlação\n",
        "correlation_matrix = df_principal[columns].corr()\n",
        "\n",
        "# Configurar o tamanho da figura\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# Plotar o heatmap da matriz de correlação\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
        "\n",
        "# Exibir o gráfico\n",
        "plt.title('Heatmap da Matriz de Correlação')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o0OL7apHglK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As colorações mais escuras são as correlações mais fortes. É possível perceber motivos que informam sobre atrasos e sobre tempo de voo são altamente correlacionados. O que possui uma correlação negativa (em azul) são as colunas relativas a clima. Se o clima é bom, ele é correlativo negativamente com tempo ruim."
      ],
      "metadata": {
        "id": "3foeoJB3hCdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para converter o valor numérico em formato HH:MM\n",
        "def convert_to_time(value):\n",
        "    if pd.isna(value):  # Verifica se o valor é NaN\n",
        "        return np.nan  # Retorna NaN para ser ignorado mais tarde\n",
        "    try:\n",
        "        value = int(value)  # Converte o valor para inteiro\n",
        "        hours = value // 100\n",
        "        minutes = value % 100\n",
        "        return f'{hours:02d}:{minutes:02d}'\n",
        "    except (ValueError, TypeError):\n",
        "        return np.nan  # Retorna NaN para valores inválidos\n",
        "\n",
        "# Aplica a função na coluna DEP_TIME\n",
        "df_principal['DEP_TIME'] = df_principal['DEP_TIME'].apply(convert_to_time)\n",
        "\n",
        "# Converte DEP_TIME para string se não estiver já no formato string\n",
        "df_principal['DEP_TIME'] = df_principal['DEP_TIME'].astype(str)\n",
        "\n",
        "# Extraí apenas as horas da coluna DEP_TIME\n",
        "df_principal['HOUR'] = df_principal['DEP_TIME'].apply(lambda x: x[:2] if x != 'nan' else np.nan)\n",
        "\n",
        "# Agrupa por hora e calcula a média de atrasos e cancelamentos, ignorando NaNs\n",
        "atrasos_por_hora = df_principal.dropna(subset=['HOUR']).groupby('HOUR')['DELAYED_DUMMY'].mean()\n",
        "cancelamentos_por_hora = df_principal.dropna(subset=['HOUR']).groupby('HOUR')['CANCELLED'].mean()\n",
        "\n",
        "# Garantir que todos os 24 horas estejam presentes no gráfico, mesmo se o valor for NaN\n",
        "all_hours = [f'{hour:02d}' for hour in range(24)]\n",
        "atrasos_por_hora = atrasos_por_hora.reindex(all_hours, fill_value=0)  # Substitui NaNs por 0\n",
        "cancelamentos_por_hora = cancelamentos_por_hora.reindex(all_hours, fill_value=0)  # Substitui NaNs por 0\n",
        "\n",
        "# Plotar os resultados\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Gráfico de atrasos\n",
        "plt.subplot(1, 2, 1)\n",
        "atrasos_por_hora.plot(kind='bar', color='blue')\n",
        "plt.title('Média de atrasos por hora')\n",
        "plt.xlabel('Hora')\n",
        "plt.ylabel('Média de atrasos')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Gráfico de cancelamentos\n",
        "plt.subplot(1, 2, 2)\n",
        "cancelamentos_por_hora.plot(kind='bar', color='red')\n",
        "plt.title('Média de cancelamentos por hora')\n",
        "plt.xlabel('Hora')\n",
        "plt.ylabel('Média de cancelamentos')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "display(df_principal['DEP_TIME'])\n",
        "len(df_principal['DEP_TIME'])"
      ],
      "metadata": {
        "id": "Z8r0O6MZmGt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao analisar o gráfico, é possível perceber que voos noturnos (entre 18h e 03h) são os que mais possuem ocorrência de atrasos e cancelamentos."
      ],
      "metadata": {
        "id": "5ybQBfe5mMwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Voos por cidade"
      ],
      "metadata": {
        "id": "JYQgp_Ba3b2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo é possível analisar as 10 cidades com maior fluxo de voos e as 10 cidades com menos fluxo de voo em janeiro de 2023 nos EUA."
      ],
      "metadata": {
        "id": "0KN_BwnA3dWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar dados por cidade\n",
        "city_counts = df_principal['ORIGIN_CITY'].value_counts().reset_index()\n",
        "city_counts.columns = ['Cidade', 'Contagem']\n",
        "\n",
        "# Ordenar as cidades pela contagem\n",
        "city_counts = city_counts.sort_values(by='Contagem', ascending=False)\n",
        "\n",
        "# Selecionar as 10 cidades com mais voos\n",
        "top_10_cities = city_counts.head(10)\n",
        "\n",
        "# Selecionar as 10 cidades com menos voos (excluindo cidades agrupadas como \"Outras\")\n",
        "bottom_10_cities = city_counts.tail(10)\n",
        "\n",
        "# Plotar as 10 cidades com mais voos\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(y='Cidade', x='Contagem', data=top_10_cities, palette='viridis')\n",
        "plt.title('Top 10 cidades com mais voos')\n",
        "plt.xlabel('Contagem de Voos')\n",
        "plt.ylabel('Cidade')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotar as 10 cidades com menos voos\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(y='Cidade', x='Contagem', data=bottom_10_cities, palette='viridis')\n",
        "plt.title('Top 10 cidades com menos voos')\n",
        "plt.xlabel('Contagem de Voos')\n",
        "plt.ylabel('Cidade')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tyGFPQEL3TKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo é possível analisar as 10 cidades com mais voos cancelados em janeiro de 2023 nos EUA."
      ],
      "metadata": {
        "id": "LGk4oeJl4S20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para incluir apenas voos cancelados\n",
        "cancelled_flights_city = df_principal[df_principal['CANCELLED'] == 1]\n",
        "\n",
        "# Contar o número de voos cancelados por cidade de origem\n",
        "city_cancel_counts = cancelled_flights_city['ORIGIN_CITY'].value_counts().reset_index()\n",
        "city_cancel_counts.columns = ['Cidade', 'Contagem']\n",
        "\n",
        "# Ordenar as cidades pela contagem de voos cancelados\n",
        "city_cancel_counts = city_cancel_counts.sort_values(by='Contagem', ascending=False)\n",
        "\n",
        "# Selecionar as 10 cidades com mais voos cancelados\n",
        "top_10_cities = city_cancel_counts.head(10)\n",
        "\n",
        "# Plotar a distribuição de voos cancelados pelas 10 cidades com mais cancelamentos\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(y='Cidade', x='Contagem', data=top_10_cities, palette='viridis')\n",
        "plt.title('Top 10 cidades com mais voos cancelados em janeiro de 2023 nos EUA')\n",
        "plt.xlabel('Contagem de voos cancelados')\n",
        "plt.ylabel('Cidade')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kYdR0Tms4Iid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No gráfico abaixo é possível analisar as 10 cidades onde tiveram mais casos de voos decolados que mudaram o destino final em janeiro de 2023 nos EUA."
      ],
      "metadata": {
        "id": "Px8FEDxf60Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para incluir apenas voos divertados\n",
        "diverted_flights_city = df_principal[df_principal['DIVERTED'] == 1]\n",
        "\n",
        "# Contar o número de voos divertados por cidade de origem\n",
        "city_divert_counts = diverted_flights_city['ORIGIN_CITY'].value_counts().reset_index()\n",
        "city_divert_counts.columns = ['Cidade', 'Contagem']\n",
        "\n",
        "# Ordenar as cidades pela contagem de voos divertados\n",
        "city_divert_counts = city_divert_counts.sort_values(by='Contagem', ascending=False)\n",
        "\n",
        "# Selecionar as 10 cidades com mais voos divertados\n",
        "top_10_cities = city_divert_counts.head(10)\n",
        "\n",
        "# Plotar a distribuição de voos divertados pelas 10 cidades com mais desviados\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(y='Cidade', x='Contagem', data=top_10_cities, palette='viridis')\n",
        "plt.title('Top 10 cidades com mais voos desviados em janeiro de 2023 nos EUA')\n",
        "plt.xlabel('Contagem de coos desviados')\n",
        "plt.ylabel('Cidade')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MKN7YK6r6Xhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Voos por estado"
      ],
      "metadata": {
        "id": "vz4N5xeK73Zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo é possível analisar a relação de estados com mais e menos voos realizados em janeiro de 2023 nos EUA."
      ],
      "metadata": {
        "id": "DHEkNb0S8W0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar Voos por Estado\n",
        "top_10_states = df_principal['ORIGIN_STATE'].value_counts().head(10)\n",
        "bottom_10_states = df_principal['ORIGIN_STATE'].value_counts().tail(10)\n",
        "\n",
        "#  Criar o Gráfico Lollipop\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.grid(False)\n",
        "plt.hlines(xmin=0, xmax=top_10_states.values, y=top_10_states.index, color='skyblue', linewidth=2)\n",
        "plt.plot(top_10_states.values, top_10_states.index, \"o\", markersize=10, color='skyblue')\n",
        "plt.title('Top 10 estados com mais voos em janeiro de 2023 nos EUA')\n",
        "plt.xlabel('Número de voos')\n",
        "plt.ylabel('Estado de origem')\n",
        "plt.show()\n",
        "\n",
        "# Criar o Gráfico Lollipop\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.grid(False)\n",
        "plt.hlines(xmin=0, xmax=bottom_10_states.values, y=bottom_10_states.index, color='lightcoral', linewidth=2)\n",
        "plt.plot(bottom_10_states.values, bottom_10_states.index, \"o\", markersize=10, color='lightcoral')\n",
        "plt.title('TTop 10 estados com menos voos em janeiro de 2023 nos EUA')\n",
        "plt.xlabel('Número de voos')\n",
        "plt.ylabel('Estado de origem')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PeVHlrS079OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico abaixo possibilita uma comparação de valores absolutos de voos cancelados nos estados do EUA referente ao mês de janeiro de 2023.\n",
        "\n"
      ],
      "metadata": {
        "id": "al78GORt9D4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para incluir apenas voos cancelados\n",
        "cancelled_flights_state = df_principal[df_principal['CANCELLED'] == 1]\n",
        "\n",
        "# Contar o número de voos cancelados por estado de origem\n",
        "state_cancel_counts = cancelled_flights_state['ORIGIN_STATE'].value_counts().reset_index()\n",
        "state_cancel_counts.columns = ['Estado', 'Contagem']\n",
        "\n",
        "# Ordenar os estados pela contagem de voos cancelados\n",
        "state_cancel_counts = state_cancel_counts.sort_values(by='Contagem', ascending=False)\n",
        "\n",
        "# Plotar a distribuição de voos cancelados por estado\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(y='Estado', x='Contagem', data=state_cancel_counts, palette='viridis')\n",
        "plt.title('Distribuição de voos cancelados por estado de origem nos EUA em janeiro de 2023')\n",
        "plt.xlabel('Contagem de voos cancelados')\n",
        "plt.ylabel('Estado')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "555n4Rmt84B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico abaixo possibilita uma comparação de valores absolutos de voos desviados nos estados do EUA referente ao mês de janeiro de 2023.\n"
      ],
      "metadata": {
        "id": "Z-f1mAqt9avr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para incluir apenas voos desviados\n",
        "diverted_flights_state = df_principal[df_principal['DIVERTED'] == 1]\n",
        "\n",
        "# Contar o número de voos desviados por estado de origem\n",
        "state_divert_counts = diverted_flights_state['ORIGIN_STATE'].value_counts().reset_index()\n",
        "state_divert_counts.columns = ['Estado', 'Contagem']\n",
        "\n",
        "# Ordenar os estados pela contagem de voos desviados\n",
        "state_divert_counts = state_divert_counts.sort_values(by='Contagem', ascending=False)\n",
        "\n",
        "# Plotar a distribuição de voos desviados por estado\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(y='Estado', x='Contagem', data=state_divert_counts, palette='viridis')\n",
        "plt.title('Distribuição de voos desviados por estado de origem em janeiro de 2023 nos EUA')\n",
        "plt.xlabel('Contagem de voos desviados da rota')\n",
        "plt.ylabel('Estado')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cmwpy20D9XoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Voos por companhia aérea"
      ],
      "metadata": {
        "id": "L_oaDchB99iL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico abaixo possibilita uma comparação de valores absolutos de voos por companhia aerea realizados nos EUA referente ao mês de janeiro de 2023."
      ],
      "metadata": {
        "id": "b57SaQGa-lFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a contagem de voos por companhia aérea\n",
        "contagens = df_principal['AIRLINE_DESCRIPTION'].value_counts()\n",
        "\n",
        "# Criar um DataFrame a partir das contagens\n",
        "df_contagens = pd.DataFrame({'AIRLINE_DESCRIPTION': contagens.index, 'Count': contagens.values})\n",
        "\n",
        "# Ordenar o DataFrame por contagem em ordem decrescente\n",
        "df_contagens = df_contagens.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Criar o gráfico de contagem usando o DataFrame ordenado\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x='AIRLINE_DESCRIPTION', y='Count', data=df_contagens, palette='viridis')\n",
        "\n",
        "# Ajustar a rotação e a posição dos rótulos do eixo x\n",
        "plt.title('Distribuição de voos por companhia aérea realizadas em janeiro de 2023 nos EUA')\n",
        "plt.xlabel('Descrição da companhia aérea')\n",
        "plt.ylabel('Contagem de voos')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Ajustar o layout para que não haja sobreposição\n",
        "plt.tight_layout()\n",
        "\n",
        "# Exibir o gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IyMOknv8-ChY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico abaixo possibilita uma comparação de voos cancelados realizados por companhia aerea nos EUA referente ao mês de janeiro de 2023."
      ],
      "metadata": {
        "id": "sBlWsTtPdxxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para incluir apenas voos cancelados\n",
        "cancelled_flights_airline = df_principal[df_principal['CANCELLED'] == 1]\n",
        "\n",
        "# Contar o número de voos cancelados por companhia aérea\n",
        "airline_cancel_counts = cancelled_flights_airline['AIRLINE_DESCRIPTION'].value_counts().reset_index()\n",
        "airline_cancel_counts.columns = ['Companhia aérea', 'Contagem']\n",
        "\n",
        "# Ordenar as companhias aéreas pela contagem de voos cancelados\n",
        "airline_cancel_counts = airline_cancel_counts.sort_values(by='Contagem', ascending=False)\n",
        "\n",
        "# Plotar a distribuição de voos cancelados por companhia aérea\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(y='Companhia aérea', x='Contagem', data=airline_cancel_counts, palette='viridis')\n",
        "plt.title('Distribuição de voos cancelados por companhia aérea referentes ao mês de janeiro de 2023 nos EUA')\n",
        "plt.xlabel('Contagem de voos cancelados')\n",
        "plt.ylabel('Companhia aérea')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uidd0Yl3-z3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico abaixo possibilita uma comparação de voos desviados realizados por companhia aerea nos EUA referente ao mês de janeiro de 2023."
      ],
      "metadata": {
        "id": "lyChMFaHeH1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para incluir apenas voos desviados\n",
        "diverted_flights_airline = df_principal[df_principal['DIVERTED'] == 1]\n",
        "\n",
        "# Contar o número de voos desviados por companhia aérea\n",
        "airline_divert_counts = diverted_flights_airline['AIRLINE_DESCRIPTION'].value_counts().reset_index()\n",
        "airline_divert_counts.columns = ['Companhia aérea', 'Contagem']\n",
        "\n",
        "# Ordenar as companhias aéreas pela contagem de voos desviados\n",
        "airline_divert_counts = airline_divert_counts.sort_values(by='Contagem', ascending=False)\n",
        "\n",
        "# Plotar a distribuição de voos desviados por companhia aérea\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(y='Companhia aérea', x='Contagem', data=airline_divert_counts, palette='viridis')\n",
        "plt.title('Distribuição de voos desviados por companhia aérea')\n",
        "plt.xlabel('Contagem de voos desviados')\n",
        "plt.ylabel('Companhia aérea')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kt--bICPeGfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No gráfico abaixo é possível analisar através da média os motivos de atrasos informados por companhia aerea.\n",
        "\n",
        "- A companhia com maior média de atrasos relacionados a operadora é a Skywest Airlines;\n",
        "- A companhia com maior média de atrasos relacionados a avião atrasado é a Frontier Airlines;"
      ],
      "metadata": {
        "id": "wxLMyj_Heeau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular as médias de atraso por companhia aérea\n",
        "df_grouped = df_principal.groupby('AIRLINE_DESCRIPTION')[['DELAY_DUE_CARRIER', 'DELAY_DUE_WEATHER', 'DELAY_DUE_NAS', 'DELAY_DUE_SECURITY', 'DELAY_DUE_LATE_AIRCRAFT']].mean()\n",
        "\n",
        "# Reformatar o DataFrame para o Seaborn\n",
        "df_melted = df_grouped.reset_index().melt(id_vars='AIRLINE_DESCRIPTION', var_name='Delay_Type', value_name='Average_Delay')\n",
        "\n",
        "# Criar o gráfico de barras com Seaborn\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=df_melted, x='AIRLINE_DESCRIPTION', y='Average_Delay', hue='Delay_Type')\n",
        "plt.xticks(rotation=45, ha='right')  # Ajustar rotação dos rótulos do eixo X\n",
        "plt.title('Média de Atrasos por Companhia Aérea e Tipo de Atraso')\n",
        "plt.ylabel('Média de Atraso (minutos)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MkQ8nkOmeafg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resultados e conclusões:"
      ],
      "metadata": {
        "id": "iWgA_asQAYgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hipótese I\n",
        "Os feriados nacionais nos EUA influenciaram no aumento dos atrasos de voos em janeiro de 2023."
      ],
      "metadata": {
        "id": "GyFFrmwOJtF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para buscar os feriados nacionais nos EUA, utilizamos a API da Holiday API. Subimos um documentos em planilha contendo os dias de janeiro de 2023 e ele realizou uma pesquisa, retornando os dias que eram feriados ou não."
      ],
      "metadata": {
        "id": "29Z0QRsaKOZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sua chave de API da Holiday API\n",
        "api_key = 'b4586703-553d-4589-8226-1d65046437bb'\n",
        "\n",
        "def verificar_feriado(data):\n",
        "    url = f\"https://holidayapi.com/v1/holidays?country=US&year={data.year}&month={data.month}&day={data.day}&key={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        dados = response.json()\n",
        "        holidays = dados.get('holidays', [])\n",
        "        if holidays:\n",
        "            return holidays[0]['name']  # Retorna o nome do primeiro feriado encontrado\n",
        "        else:\n",
        "            return \"Nenhum feriado\"\n",
        "    else:\n",
        "        print(f\"Erro ao obter dados para {data}: {response.status_code}\")\n",
        "        return \"Erro\"\n",
        "\n",
        "# Converter a coluna FL_DATE para datetime\n",
        "df2['FL_DATE'] = pd.to_datetime(df2['FL_DATE'], errors='coerce')\n",
        "\n",
        "# Adicionar a coluna 'feriado' no df2\n",
        "df2['feriado'] = df2['FL_DATE'].apply(verificar_feriado)\n",
        "\n",
        "print(df2)"
      ],
      "metadata": {
        "id": "EfWT8gvIJ6a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A API retornou tanto feriados nacionais quanto feriados religiosos. Como o foco da análise eram feriados nacionais, foi realizado um ajuste nas informações. Neste sentido, foram considerados somente os feriados abaixo:\n",
        "\n",
        "\n",
        "*   Feriado de ano-novo;\n",
        "*   Feriado de Martin Luther King Jr;\n",
        "\n",
        "Para realizar as modificações necessárias utilizamos a ferramenta Excel. Foi modificado o feriado de \"Seventh Day of Kwanzaa\" para \"New Year's day\" e adicionado uma coluna chamada \"nacional_holiday_dummy\", onde 1 era para feriados nacionais e 0 para o restante.\n",
        "\n",
        "Subimos o novo arquivo como df_feriados=feriados.xlsx\n",
        "\n",
        "**Informação interessante:** Quando o feriado cai em um final de semana nos EUA, a próxima segunda-feira é considerada feriado. No ano de 2023 o feriado de Ano Novo caiu em um domingo. Nesse sentido, a segunda-feira, 02/01, foi considerado também como feriado nacional.\n",
        "\n"
      ],
      "metadata": {
        "id": "GnzkPS-9K0Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unir o resultado de feriados com o arquivo de aeroportos, assim facilitando no momento de realizar análises em outras plataformas.\n",
        "\n",
        "# Converter colunas FL_DATE para datetime\n",
        "df6['FL_DATE'] = pd.to_datetime(df6['FL_DATE'])\n",
        "df2['FL_DATE'] = pd.to_datetime(df2['FL_DATE'])\n",
        "\n",
        "# Realizar o merge\n",
        "df_left = pd.merge(df6, df2, on='FL_DATE', how='left')\n",
        "display(df_left)"
      ],
      "metadata": {
        "id": "G0c2bOB3XHW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a união do bancos de dados, foi reaizado análises estatisticas. O teste escolhido foi o de Mann-Whitney, onde permite verificar se há uma diferença estatisticamente significativa entre as médias dos atrasos nos dois grupos (atraso em feriados e não feriados)."
      ],
      "metadata": {
        "id": "rTKLV7KjYr4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separação dos Dados em Dias de Feriado e Não Feriado\n",
        "dias_feriado = df_principal[df_principal['NATIONAL_HOLIDAY_DUMMY'] == 1]\n",
        "dias_nao_feriado = df_principal[df_principal['NATIONAL_HOLIDAY_DUMMY'] == 0]\n",
        "\n",
        "#Comparação dos Atrasos Entre os Dois Grupos\n",
        "media_atrasos_feriado = dias_feriado['DELAYED_DUMMY'].mean()\n",
        "media_atrasos_nao_feriado = dias_nao_feriado['DELAYED_DUMMY'].mean()\n",
        "\n",
        "print(f'Média de atrasos em dias de feriado: {media_atrasos_feriado}')\n",
        "print(f'Média de atrasos em dias não feriado: {media_atrasos_nao_feriado}')\n",
        "\n",
        "# Teste de Mann-Whitney\n",
        "u_stat, p_value = stats.mannwhitneyu(dias_feriado['DELAYED_DUMMY'].dropna(), dias_nao_feriado['DELAYED_DUMMY'].dropna())\n",
        "\n",
        "print(f'Estatística U: {u_stat}')\n",
        "print(f'Valor-p: {p_value}')"
      ],
      "metadata": {
        "id": "AtHJGlrnYXix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi usado a biblioteca Pandas para criar uma tabela de contingência. Esta tabela mostra a frequência de ocorrências combinadas de NATIONAL_HOLIDAY_DUMMY (dias de feriado ou não) e DELAYED_DUMMY (voos atrasados ou não)."
      ],
      "metadata": {
        "id": "zfvqyOvlbaf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar ocorrências\n",
        "contingencia = pd.crosstab(df_principal['NATIONAL_HOLIDAY_DUMMY'], df_principal['DELAYED_DUMMY'])\n",
        "\n",
        "display(contingencia)"
      ],
      "metadata": {
        "id": "nY7Smc3dbNux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O teste Qui-Quadrado verifica se há uma associação significativa entre as duas variáveis categóricas."
      ],
      "metadata": {
        "id": "06QuQaDkbvpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste Qui-Quadrado\n",
        "chi2, p_value, _, _ = chi2_contingency(contingencia)\n",
        "print(f'Estatística Qui-Quadrado: {chi2}')\n",
        "print(f'Valor-p: {p_value}')\n"
      ],
      "metadata": {
        "id": "ESsOTJegbqn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para finalizar a analise da hipótese, foi realizado Risco Relativo. O Risco Relativo é uma medida estatística usada para comparar a probabilidade de um evento ocorrer em dois grupos diferentes."
      ],
      "metadata": {
        "id": "SXorDsG-e8W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A - Calcular a taxa de atraso em feriados\n",
        "a3 = df_principal[((df_principal['NATIONAL_HOLIDAY_DUMMY'] == 1)) & (df_principal['DELAYED_DUMMY'] == 1)].shape[0]\n",
        "\n",
        "# B - Calcular a taxa de não atraso em feriados\n",
        "b3 = df_principal[((df_principal['NATIONAL_HOLIDAY_DUMMY'] == 1)) & (df_principal['DELAYED_DUMMY'] == 0)].shape[0]\n",
        "\n",
        "# C - Calcular a taxa de atraso em dias normais\n",
        "c3 = df_principal[(df_principal['NATIONAL_HOLIDAY_DUMMY'] == 0) & (df_principal['DELAYED_DUMMY'] == 1)].shape[0]\n",
        "\n",
        "# D - Calcular a taxa de não atraso em dias normais\n",
        "d3 = df_principal[(df_principal['NATIONAL_HOLIDAY_DUMMY'] == 0) & (df_principal['DELAYED_DUMMY'] == 0)].shape[0]\n",
        "\n",
        "#Calculo Risco Relativo\n",
        "risk_relative = (a3/(a3+b3)) / (c3/(c3+d3))\n",
        "\n",
        "print(risk_relative)\n",
        "print(a3)\n",
        "print(b3)\n",
        "print(c3)\n",
        "print(d3)\n",
        "print(f'O risco relativo de um voo atrasar é de {risk_relative}. Isso significa que quando é feriado, são {(risk_relative - 1) * 100:.0f}% maiores os riscos do voo sair atrasado.')"
      ],
      "metadata": {
        "id": "LopuA3Ljd2SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Portanto, os voos realizados em feriados em janeiro de 2023 possuiam 26% de chances de atraso. Neste sentido a hipótese de feriados nacionais influenciaram no aumento de atrasos de voos em janeiro de 2023 é verdadeira.\n",
        "\n",
        "Questões como cultura, clima, sazonalidade devem ser considerados no momento da análise. Neste sentido, generalizar esta hipótese para os demais feriados nacionais nos EUA é insuficiente."
      ],
      "metadata": {
        "id": "2ArFI97Sfsfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hipótese II\n",
        "Condições climáticas adversas, como névoa, chuva de forte intensidade, fumaça, tempestade, tempestade com chuva forte e tempestade com chuva leve, foram fatores determinantes para o aumento do número de cancelamentos de voos em janeiro de 2023.\n",
        "\n"
      ],
      "metadata": {
        "id": "vHFAEWGS5nLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A - Calcular a taxa de cancelamento em condições climáticas ruins\n",
        "a = df_principal[(df_principal['CLIMATE_DANGEROUS'] == 1) & (df_principal['CANCELLED'] == 1)].shape[0]\n",
        "\n",
        "# B - Calcular a taxa de não cancelamento em condições climáticas ruins\n",
        "b = df_principal[(df_principal['CLIMATE_DANGEROUS'] == 1) & (df_principal['CANCELLED'] == 0)].shape[0]\n",
        "\n",
        "# c - Calcular a taxa de cancelamento em condições climáticas boas\n",
        "c = df_principal[((df_principal['CLIMATE_ACCEPTABLE'] == 1) | (df_principal['CLIMATE_GOOD'] == 1)) & (df_principal['CANCELLED'] == 1)].shape[0]\n",
        "\n",
        "# D - Calcular a taxa de não cancelamento em condições climáticas boas\n",
        "d = df_principal[((df_principal['CLIMATE_ACCEPTABLE'] == 1) | (df_principal['CLIMATE_GOOD'] == 1)) & (df_principal['CANCELLED'] == 0)].shape[0]\n",
        "\n",
        "#Calculo Risco Relativo\n",
        "risk_relative = (a/(a+b)) / (c/(c+d))\n",
        "\n",
        "print(risk_relative)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(d)\n",
        "print(f'O risco relativo de um voo cancelar é de {risk_relative}. Isso significa que quando o tempo é considerado ruim, são {(risk_relative - 1) * 100:.0f}% maiores os riscos do voo ser cancelado.')"
      ],
      "metadata": {
        "id": "YMw3yThEjqkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hipótese III\n",
        "As cinco companhias aéreas com maior fluxo de voos domésticos estão relacionadas com as maiores taxas de atraso em janeiro de 2023 nos EUA.\n"
      ],
      "metadata": {
        "id": "T7xZxlZF55nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar crosstab para criar a tabela de contingência\n",
        "tabela_contingencia_three = pd.crosstab(df_principal['AIRLINE_DESCRIPTION'], df_principal['DELAYED_DUMMY'])\n",
        "\n",
        "# Exibir a tabela de contingência\n",
        "print(tabela_contingencia_three)\n",
        "\n",
        "# Realizar o teste qui-quadrado\n",
        "chi2_three, p_three, dof_three, expected_three = chi2_contingency(tabela_contingencia_three)\n",
        "\n",
        "print(f\"Chi-square: {chi2_three}\")\n",
        "print(f\"P-value: {p_three}\")\n",
        "print(f\"Degrees of freedom: {dof_three}\")\n",
        "#print(\"Expected frequencies:\")\n",
        "#print(expected_three )"
      ],
      "metadata": {
        "id": "ACFd729fqyHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hipótese IV\n",
        "Os cinco aeroportos com maior fluxo de voos em janeiro de 2023 são os que mais sofreram cancelamentos durante este período.\n",
        "\n"
      ],
      "metadata": {
        "id": "sS5P1QFM57bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação da tabela de contingência diretamente\n",
        "contingency_table = pd.crosstab(df_principal['ORIGIN'], df_principal['CANCELLED'])\n",
        "\n",
        "# Seleção dos cinco aeroportos com maior fluxo de voos\n",
        "top_airports = contingency_table.sum(axis=1).nlargest(5).index.tolist()\n",
        "\n",
        "# Filtragem da tabela de contingência apenas para os top 5 aeroportos\n",
        "contingency_table_top5 = contingency_table.loc[top_airports]\n",
        "\n",
        "# Aplicação do teste qui-quadrado de independência\n",
        "chi2, p_val, dof, expected = chi2_contingency(contingency_table_top5)\n",
        "\n",
        "print(f'Valor qui-quadrado: {chi2}')\n",
        "print(f'Valor-p: {p_val}')\n",
        "print(f'Graus de liberdade: {dof}')\n",
        "print('Tabela de valores esperados:')\n",
        "print(expected)"
      ],
      "metadata": {
        "id": "81DNcEY-zxvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Limitações e conclusões"
      ],
      "metadata": {
        "id": "sdG_QYEDmA80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limitações encontradas:\n",
        "\n",
        "- Corte temporal de somente um mês no ano (janeiro de 2023);\n",
        "- Falta de informação sobre a quantidade de passageiros;\n",
        "- Sem ID unico de cada voo informado no dataset.\n",
        "- **FL_CODE** (codigo companhia aerea + número de voo) não são valores únicos. existem casos na qual o mesmo fl_code possui origens e destinos diferentes.\n",
        "- Voos realizados somente em um corte específico de tempo (janeiro de 2023), sendo difícil gerar predições concretas.\n",
        "- Valores nulos relativos a atraso no dataset eram importantes para análises referente a este evento. Muitos valores omitidos. Se estes valores fossem informados, possivelmente as análises realizadas sobre os motivos de atraso gerariam informações diferentes.\n",
        "\n",
        "Recomendações:\n",
        "- Utilização de ferramentas para BigData, visto que o arquivo é grande e demanda tempo e recursos para manipulação em ferramentas básicas;\n",
        "- Cruzar informações com outros meses do ano, para assim gerar predições mais concretas referentes as companhias aéreas e aeroportos;\n",
        "\n",
        "Conclusões:\n",
        "- Feriados modificam a logística do aeroporto e da companhia aérea. Nestes dias atípicos é necessária uma atenção redobrada nos processos;\n",
        "- Condições climáticas adversas possuem valores baixos de taxa de cancelamento, não tão significativas quanto o esperado;\n",
        "- A maior capacidade do aeroporto possui relação com o quantidade cancelamento dos voos, entretanto não tão significativo quanto o esperado. Cancelamentos geralmente estão relacionados com a segurança da operação do voo e maiores aeroportos possuem maiores fluxos de voo, logicamente possuindo uma quantidade maior de cancelamentos. Entretanto ao analisar a taxa de cancelamento por aeroportos o ranking apresenta aeroportos não reconhecidos como de alto fluxo. Para reconhecer os motivos desta diferença é necessária uma análise mais robusta.\n",
        "- No turno da noite ocorre um pico de cancelamentos e atrasos. Necessário maiores análises para reconhecer possíveis motivos;\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S2WHYyS-mHz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Materiais gerados:\n"
      ],
      "metadata": {
        "id": "Agk2VdVmHiKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Dashboard no Power BI;](https://app.powerbi.com/view?r=eyJrIjoiMTNhMmQ1M2YtN2U4NS00Mjg0LTgxOTktZTY0OWQ2MDIzZTY1IiwidCI6IjUwMDJiOThmLTY5MGUtNDI1ZC05ZDMyLTY2ZDg0OTU4NTZlOSJ9)\n",
        "- [Apresentação de slide para os clientes;](https:docs.google.com/presentation/d/1dBX1fcdJjYKbyS0QG4wKTaRdpMbQ05BcOvxwtHQVoJY/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "0UjW01HIJqKe"
      }
    }
  ]
}